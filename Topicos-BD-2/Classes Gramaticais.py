import streamlit as st
import spacy
from pathlib import Path
import pdfplumber
import pandas as pd
import plotly.express as px
from collections import Counter
import tempfile
import os

# Tenta encontrar a raiz do projeto: sobe at√© encontrar a pasta 'styles' ou 'images'
def find_project_root(current_path):
    # Sobe at√© encontrar a raiz (onde est√£o as pastas styles e images)
    for parent in [current_path] + list(current_path.parents):
        if (parent / "styles").exists() and (parent / "images").exists():
            return parent
    return current_path  # fallback

# Obt√©m o diret√≥rio atual do script
current_dir = Path(__file__).parent if "__file__" in locals() else Path.cwd()
project_root = find_project_root(current_dir)

# Constr√≥i caminhos absolutos para os arquivos
css_path = project_root / "styles" / "styles.css"

@st.cache_resource
def load_spacy_model():
    try:
        return spacy.load("pt_core_news_sm")
    except OSError:
        try:
            st.info("Modelo portugu√™s n√£o dispon√≠vel. Usando modelo em ingl√™s...")
            return spacy.load("en_core_web_sm")
        except OSError:
            st.warning("Usando modelo b√°sico do spaCy (funcionalidades limitadas)")
            return spacy.blank("pt")

nlp = load_spacy_model()

def load_css(css_path):
    try:
        with open(css_path, "r", encoding="utf-8") as f:
            css_content = f.read()
            st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        st.error("Arquivo CSS n√£o encontrado na pasta 'styles/'")
    except Exception as e:
        st.error(f"Erro ao carregar CSS: {e}")
load_css(css_path)

st.title("üìù Marca√ß√£o de Classes Gramaticais")

# Mover explica√ß√£o para o topo
st.write("""
## Marca√ß√£o de Classes Gramaticais (POS Tagging)

T√©cnica que atribui etiquetas gramaticais a cada palavra em um texto.

### Categorias comuns:
- **Substantivos** (NN): pessoas, lugares, coisas
- **Verbos** (VB): a√ß√µes e estados
- **Adjetivos** (JJ): qualidades e caracter√≠sticas
- **Adv√©rbios** (RB): modifica√ß√£o de verbos, adjetivos

### Aplica√ß√µes:
- An√°lise sint√°tica
- Tradu√ß√£o autom√°tica
- Corre√ß√£o gramatical
- An√°lise de estilo liter√°rio
""")

# Adicionar se√ß√£o de upload de PDF
st.header("An√°lise de Arquivos PDF")

uploaded_file = st.file_uploader(
    "Carregue um arquivo PDF para an√°lise gramatical",
    type="pdf",
    help="Tamanho m√°ximo: 200MB"
)

def extract_text_from_pdf(uploaded_file):
    """Extrai texto de um arquivo PDF carregado"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        text = ""
        with pdfplumber.open(tmp_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        
        os.unlink(tmp_path)  # Remove arquivo tempor√°rio
        return text.strip()
    
    except Exception as e:
        st.error(f"Erro ao extrair texto do PDF: {e}")
        return None

def analyze_grammar(text):
    """Executa an√°lise gramatical completa no texto"""
    doc = nlp(text)
    
    # Estat√≠sticas b√°sicas
    total_tokens = len(doc)
    sentences = list(doc.sents)
    total_sentences = len(sentences)
    
    # Contagem de classes gramaticais
    pos_counts = Counter(token.pos_ for token in doc)
    
    # An√°lise detalhada
    grammar_data = []
    for token in doc:
        if not token.is_space:
            grammar_data.append({
                "Texto": token.text,
                "Lemma": token.lemma_,
                "Classe Gramatical": token.pos_,
                "Tag Detalhada": token.tag_,
                "Depend√™ncia": token.dep_,
                "Forma": token.shape_,
                "√â Alpha": token.is_alpha,
                "√â Stopword": token.is_stop
            })
    
    return {
        "doc": doc,
        "stats": {
            "total_tokens": total_tokens,
            "total_sentences": total_sentences,
            "pos_counts": pos_counts
        },
        "grammar_data": grammar_data
    }

def create_visualizations(pos_counts):
    """Cria visualiza√ß√µes para as estat√≠sticas gramaticais"""
    if pos_counts:
        df = pd.DataFrame({
            "Classe Gramatical": list(pos_counts.keys()),
            "Quantidade": list(pos_counts.values())
        })
        
        fig_bar = px.bar(
            df,
            x="Classe Gramatical",
            y="Quantidade",
            title="Distribui√ß√£o de Classes Gramaticais",
            color="Classe Gramatical"
        )
        
        fig_pie = px.pie(
            df,
            values="Quantidade",
            names="Classe Gramatical",
            title="Propor√ß√£o de Classes Gramaticais"
        )
        
        return fig_bar, fig_pie
    
    return None, None

# Tabelas de legenda para Classes Gramaticais e Depend√™ncias
POS_LEGEND = {
    "ADJ": "Adjetivo",
    "ADP": "Adposi√ß√£o",
    "ADV": "Adv√©rbio",
    "AUX": "Verbo auxiliar",
    "CONJ": "Conjun√ß√£o",
    "CCONJ": "Conjun√ß√£o coordenativa",
    "DET": "Determinante",
    "INTJ": "Interjei√ß√£o",
    "NOUN": "Substantivo",
    "NUM": "Numeral",
    "PART": "Part√≠cula",
    "PRON": "Pronome",
    "PROPN": "Nome pr√≥prio",
    "PUNCT": "Pontua√ß√£o",
    "SCONJ": "Conjun√ß√£o subordinativa",
    "SYM": "S√≠mbolo",
    "VERB": "Verbo",
    "X": "Outro",
    "SPACE": "Espa√ßo"
}

DEP_LEGEND = {
    "acl": "Cl√°usula adnominal",
    "advcl": "Cl√°usula adverbial",
    "advmod": "Modificador adverbial",
    "amod": "Modificador adjetival",
    "appos": "Aposi√ß√£o",
    "aux": "Auxiliar",
    "case": "Caso",
    "cc": "Conjun√ß√£o coordenativa",
    "ccomp": "Complemento clausal",
    "clf": "Classificador",
    "compound": "Composto",
    "conj": "Conjun√ß√£o",
    "cop": "C√≥pula",
    "csubj": "Sujeito clausal",
    "dep": "Depend√™ncia n√£o especificada",
    "det": "Determinante",
    "discourse": "Elemento discursivo",
    "dislocated": "Deslocado",
    "expl": "Expletivo",
    "fixed": "Express√£o fixa",
    "flat": "Nome flat",
    "goeswith": "Goes with",
    "iobj": "Objeto indireto",
    "list": "Lista",
    "mark": "Marcador",
    "nmod": "Modificador nominal",
    "nsubj": "Sujeito nominal",
    "nummod": "Modificador num√©rico",
    "obj": "Objeto",
    "obl": "Obl√≠quo",
    "orphan": "√ìrf√£o",
    "parataxis": "Parataxe",
    "punct": "Pontua√ß√£o",
    "reparandum": "Reparandum",
    "root": "Raiz",
    "vocative": "Vocativo",
    "xcomp": "Complemento clausal aberto"
}

if uploaded_file is not None:
    with st.spinner("Processando PDF..."):
        # Extrair texto
        text = extract_text_from_pdf(uploaded_file)
        
        if text:
            st.success("Texto extra√≠do com sucesso!")
            
            # Analisar gram√°tica
            analysis = analyze_grammar(text)
            
            # Mostrar estat√≠sticas
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total de Palavras", analysis["stats"]["total_tokens"])
            with col2:
                st.metric("Total de Senten√ßas", analysis["stats"]["total_sentences"])
            with col3:
                st.metric("Classes Gramaticais √önicas", len(analysis["stats"]["pos_counts"]))
            
            # Visualiza√ß√µes - uma abaixo da outra
            st.subheader("Visualiza√ß√µes")
            fig_bar, fig_pie = create_visualizations(analysis["stats"]["pos_counts"])
            
            if fig_bar and fig_pie:
                st.plotly_chart(fig_bar, use_container_width=True)
                st.plotly_chart(fig_pie, use_container_width=True)
            
            # Tabela detalhada
            st.subheader("An√°lise Detalhada")
            df_grammar = pd.DataFrame(analysis["grammar_data"])
            st.dataframe(df_grammar, use_container_width=True)
            
            # Tabelas de legenda
            st.subheader("Legendas")
            col_legend1, col_legend2 = st.columns(2)
            
            with col_legend1:
                st.write("**Classes Gramaticais**")
                pos_legend_df = pd.DataFrame([
                    {"Sigla": sigla, "Significado": significado} 
                    for sigla, significado in POS_LEGEND.items()
                ])
                st.dataframe(pos_legend_df, use_container_width=True, height=400)
            
            with col_legend2:
                st.write("**Depend√™ncias Sint√°ticas**")
                dep_legend_df = pd.DataFrame([
                    {"Sigla": sigla, "Significado": significado} 
                    for sigla, significado in DEP_LEGEND.items()
                ])
                st.dataframe(dep_legend_df, use_container_width=True, height=400)
            
            # Download dos resultados
            st.subheader("Exportar Resultados")
            csv_data = df_grammar.to_csv(index=False).encode("utf-8")
            st.download_button(
                label="üì• Download como CSV",
                data=csv_data,
                file_name="analise_gramatical.csv",
                mime="text/csv"
            )
        else:
            st.error("N√£o foi poss√≠vel extrair texto do PDF")
