Uma Abordagem em Etapa de Processamento para ReduÃ§Ã£o do
ViÃ©s de Popularidade
Rodrigo Ferrari de Souza
Universidade de SÃ£o Paulo
SÃ£o Carlos-SP, Brasil
rodrigofsouza@usp.br
Marcelo Garcia Manzato
Universidade de SÃ£o Paulo
SÃ£o Carlos-SP, Brasil
mmanzato@icmc.usp.br
WebMediaâ€™2024, Juiz de Fora, Brazil
Rodrigo Ferrari de Souza and Marcelo Garcia Manzato
Figura 1: RepresentaÃ§Ã£o de trÃªs possÃ­veis cenÃ¡rios de geraÃ§Ã£o de recomendaÃ§Ãµes.
â€¢ Em processamento: A calibraÃ§Ã£o nesta etapa envolve a mo-
dificaÃ§Ã£o ou introduÃ§Ã£o de novos algoritmos com o objetivo
de reduzir vieses no modelo durante o treinamento.
Dessa forma, a estratÃ©gia estudada neste trabalho foi a estratÃ©gia
de calibraÃ§Ã£o em etapa de processamento. Esse tipo de estratÃ©gia
visa modificar algoritmos existentes ou introduzir novos algoritmos
que resultem em classificaÃ§Ãµes e recomendaÃ§Ãµes justas, por exemplo,
removendo preconceitos e discriminaÃ§Ã£o durante o processo de
treinamento do modelo. Normalmente, tais mÃ©todos visam aprender
um modelo sem vieses, ao mesmo tempo que consideram a justiÃ§a,
incorporando mudanÃ§as na funÃ§Ã£o objetivo de um algoritmo por
um termo de justiÃ§a ou impondo restriÃ§Ãµes de justiÃ§a [19].
A abordagem BPR (Bayesian Personalized Ranking for Implicit Fe-
edback) [20] Ã© uma tÃ©cnica LTR (Learning to Rank) do tipo pairwise
que procura posicionar itens relevantes no topo da lista de reco-
mendaÃ§Ã£o. Para isso, sÃ£o feitas comparaÃ§Ãµes entre pares de itens
â€“ um conhecido e outro desconhecido pelo usuÃ¡rio â€“ de modo a
maximizar a diferenÃ§a de suas respectivas representaÃ§Ãµes. Apesar
de nÃ£o lidar com injustiÃ§a e vieses, o BPR possui uma flexibili-
dade em sua construÃ§Ã£o que permite utilizaÃ§Ã£o com outros modelos
de recomendaÃ§Ã£o, e tambÃ©m extensÃµes para que outras condiÃ§Ãµes
(como vieses e injustiÃ§a) sejam impostas durante seu treinamento
[3]. PorÃ©m, conforme relatado na seÃ§Ã£o de trabalhos relacionados,
hÃ¡ uma deficiÃªncia de trabalhos em etapa de processamento que
sejam capazes de lidar com diferentes aspectos de justiÃ§a e vieses.
Assim, a proposta deste trabalho Ã© combinar uma forma de ca-
libraÃ§Ã£o personalizada baseada na popularidade dos itens com o
mÃ©todo BPR [20] em etapa de processamento. O objetivo dessa
combinaÃ§Ã£o Ã© trazer um sistema eficiente que traga recomendaÃ§Ãµes
coerentes com as preferÃªncias dos usuÃ¡rios, reduza o viÃ©s de popu-
laridade e se aproveite do mecanismo de otimizaÃ§Ã£o de ranking das
recomendaÃ§Ãµes de acordo com a relevÃ¢ncia dos itens.
A estrutura deste trabalho Ã© a seguinte: na SeÃ§Ã£o 2, discutimos
trabalhos relacionados e comparamos as abordagens existentes com
o nosso trabalho. A SeÃ§Ã£o 3 descreve a estrutura para nossas pro-
posta de calibraÃ§Ã£o. A SeÃ§Ã£o 4 detalha a metodologia de avaliaÃ§Ã£o
do sistema proposto. A SeÃ§Ã£o 5 discute os resultados obtidos. Final-
mente, na SeÃ§Ã£o 6, concluÃ­mos nosso estudo, apresentando algumas
direÃ§Ãµes futuras para pesquisas.
TRABALHOS RELACIONADOS
A literatura recente apresenta diversas propostas destinadas a cali-
brar recomendaÃ§Ãµes para alinhÃ¡-las de forma mais consistente com
os perfis dos usuÃ¡rios. Conforme [19], Ã© possÃ­vel aplicar a calibraÃ§Ã£o
em trÃªs diferentes etapas, que serÃ£o detalhadas a seguir.
2.1
Etapa de PrÃ©-Processamento
Essa etapa consiste em alterar os dados a serem utilizados pelo
sistema antes das recomendaÃ§Ãµes serem geradas. Possui vantagens
como: ajuda a melhorar a qualidade dos dados removendo as incon-
sistÃªncias antes de serem utilizados e pode melhorar a eficiÃªncia
do tempo de processamento e adaptar os dados Ã s necessidades do
algoritmo. Apesar disso, esses ajustes podem aumentar o tempo de
preparaÃ§Ã£o do sistema e levar a perda de informaÃ§Ãµes importantes
dos dados a serem utilizados.
O trabalho [14] apresenta uma abordagem de omissÃ£o de atri-
butos para tentar remover o viÃ©s nos dados. AlÃ©m disso, o mesmo
trabalho mostra uma estratÃ©gia de alteraÃ§Ã£o dos rÃ³tulos dos itens
para remover os vieses. Por outro lado, essas tÃ©cnicas podem ser in-
suficientes para garantir justiÃ§a nas recomendaÃ§Ãµes, alÃ©m de existir
a possibilidade de tais mÃ©todos reduzirem a acurÃ¡cia do sistema.
Uma outra estratÃ©gia Ã© apresentada no trabalho [22], onde Ã©
proposto um algoritmo baseado em seleÃ§Ã£o de amostras para um
treinamento justo e robusto. Para tanto, Ã© formulado um problema
de otimizaÃ§Ã£o combinatÃ³ria para a seleÃ§Ã£o imparcial de amostras na
presenÃ§a de problemas nos dados de treinamento. Um dos principais
riscos dessa seleÃ§Ã£o de amostras Ã© a introduÃ§Ã£o de injustiÃ§as, caso o
procedimento de amostragem nÃ£o seja cuidadosamente projetado,
jÃ¡ que se a seleÃ§Ã£o for tendenciosa para determinados grupos de
dados, o modelo treinado tambÃ©m poderÃ¡ apresentar vieses. Um
outro problema Ã© o custo computacional dessa seleÃ§Ã£o de amostras
e a complexidade para realizar essa seleÃ§Ã£o dependendo do contexto
dos dados.
2.2
Etapa de PÃ³s-Processamento
A etapa de pÃ³s-processamento consiste em calibrar o sistema apÃ³s o
modelo ter gerado as recomendaÃ§Ãµes e tem as seguintes vantagens:
Ã© independente do algoritmo de recomendaÃ§Ã£o, pois pode ser feita
uma reclassificaÃ§Ã£o da lista gerada por qualquer outro modelo; tam-
bÃ©m Ã© mais eficiente, porque nÃ£o afeta o tempo de processamento
do algoritmo que gera as recomendaÃ§Ãµes. Todavia, essa etapa pode
reduzir a precisÃ£o do sistema jÃ¡ que altera a lista calibrada gerada
pelo modelo de recomendaÃ§Ã£o.
Trabalhos como [24] e [9] fazem ajustes com base nos interesses
dos usuÃ¡rios nos gÃªneros de itens para alcanÃ§ar um sistema mais
consistente. Apesar do foco na consistÃªncia, esses trabalhos nÃ£o
abordam a questÃ£o do viÃ©s de popularidade.
Uma Abordagem em Etapa de Processamento para ReduÃ§Ã£o do ViÃ©s de Popularidade
WebMediaâ€™2024, Juiz de Fora, Brazil
Para abordar o viÃ©s de popularidade, alguns trabalhos implemen-
tam estratÃ©gias de calibraÃ§Ã£o nessa etapa, como o artigo [23] que
apresenta uma proposta de calibraÃ§Ã£o baseada em chaveamento.
Esta abordagem opta pela calibraÃ§Ã£o com base na popularidade dos
itens ou nos gÃªneros dos itens. Por outro lado, conforme menci-
onado anteriormente, a precisÃ£o do sistema pode ser afetada, jÃ¡
que hÃ¡ uma reordenaÃ§Ã£o na lista de itens sugeridos apÃ³s a etapa de
recomendaÃ§Ã£o.
2.3
Etapa de Processamento
Na etapa de processamento, a calibraÃ§Ã£o ocorre junto com o trei-
namento e geraÃ§Ã£o das recomendaÃ§Ãµes, e pode levar a um melhor
desempenho do algoritmo em termos de precisÃ£o. AlÃ©m disso, tam-
bÃ©m permite aplicar diferentes tÃ©cnicas de mitigaÃ§Ã£o da injustiÃ§a
durante o treinamento do algoritmo. Entretanto, esses ajustes po-
dem aumentar a complexidade e o tempo de treinamento do sistema.
As abordagens existentes na literatura normalmente usam apren-
dizado de mÃ¡quina para construir modelos de classificaÃ§Ã£o. Em geral,
esses modelos categorizam listas nÃ£o vistas de forma semelhante Ã 
classificaÃ§Ã£o dos dados de treinamento. O objetivo geral Ã© ter um
modelo que minimize uma funÃ§Ã£o de perda que capture a distÃ¢ncia
entre o que foi aprendido e a classificaÃ§Ã£o de entrada [19].
O trabalho [30] segue essa ideia adicionando termos de regula-
rizaÃ§Ã£o, que expressam medidas de injustiÃ§a que o modelo deve
minimizar alÃ©m da minimizaÃ§Ã£o da funÃ§Ã£o de perda original. Outra
abordagem apresentada Ã© vista em [16], que utiliza a estratÃ©gia de
rede neural artificial denominada variational autoencoders (VAE).
Nessa abordagem a filtragem colaborativa Ã© feita juntamente com
parÃ¢metros de regularizaÃ§Ã£o que melhoram a representaÃ§Ã£o dos
dados implementados pelo modelo.
O trabalho [3] propÃµe uma abordagem para reduzir o viÃ©s de
popularidade em sistemas de recomendaÃ§Ã£o. O mÃ©todo apresen-
tado conecta as perspectivas do usuÃ¡rio e do item para minimizar a
correlaÃ§Ã£o entre a popularidade de um item e sua relevÃ¢ncia para
um usuÃ¡rio especÃ­fico. Isso Ã© feito por meio de um modelo probabi-
lÃ­stico que aprende os fatores latentes dos usuÃ¡rios e dos itens. O
algoritmo atualiza os fatores do usuÃ¡rio com base na diferenÃ§a entre
a avaliaÃ§Ã£o do usuÃ¡rio para dois itens (popular e menos popular) e
a probabilidade prevista de o usuÃ¡rio preferir o item menos popular.
Devido Ã  similaridade com a proposta deste trabalho, o mÃ©todo foi
usado como um dos baselines desta pesquisa.
Existem estratÃ©gias alternativas para gerar recomendaÃ§Ãµes mais
consistentes. A proposta [12] emprega grafos para mitigar injustiÃ§as
no sistema, considerando o gÃªnero do usuÃ¡rio. O trabalho [6] imple-
menta uma abordagem pareada considerando a justiÃ§a entre grupos
de itens, ajustando a lista de recomendaÃ§Ãµes durante o treinamento.
A abordagem [17] sugere a utilizaÃ§Ã£o de grafos e redes neurais para
atribuir pesos aos itens recomendados, equilibrando-os de acordo
com as preferÃªncias do usuÃ¡rio.
Embora essas abordagens produzam resultados interessantes,
os estudos nÃ£o abordam o viÃ©s de popularidade de forma a trazer
recomendaÃ§Ãµes que atendam os interesses dos usuÃ¡rios por esse
aspecto, havendo uma lacuna na Ã¡rea com relaÃ§Ã£o a sistemas que
tragam recomendaÃ§Ãµes coerentes e que lidem com o viÃ©s de popu-
laridade em etapa de processamento. AlÃ©m disso, o trabalho [11]
destaca a importÃ¢ncia dos vieses e como eles afetam os sistemas,
o que faz ser necessÃ¡rio selecionar mÃ©todos adequados para lidar
com o viÃ©s presente no sistema.
Dessa forma, a estratÃ©gia deste trabalho Ã© combinar uma forma
de calibraÃ§Ã£o personalizada baseada na popularidade dos itens com
o mÃ©todo BPR [20] em etapa de processamento. O objetivo dessa
combinaÃ§Ã£o Ã© trazer um sistema eficiente que traga recomendaÃ§Ãµes
coerentes, reduza o viÃ©s de popularidade e seja capaz de fornecer
recomendaÃ§Ãµes relevantes de acordo com o perfil de cada usuÃ¡rio.
As prÃ³ximas seÃ§Ãµes descrevem a implementaÃ§Ã£o dessa combinaÃ§Ã£o
e os resultados dessa abordagem.
ESTRATÃ‰GIA DE CALIBRAÃ‡ÃƒO
Supondo que hÃ¡ um conjunto de itens ğ¼= {ğ‘–1,ğ‘–2, ...,ğ‘–|ğ¼|}, um con-
junto de usuÃ¡rios ğ‘ˆ= {ğ‘¢1,ğ‘¢2, ...,ğ‘¢|ğ‘ˆ|} e um conjunto de itens
candidatos para cada usuÃ¡rio ğ¶ğ¼ğ‘¢= {ğ‘–1,ğ‘–2, ...,ğ‘–ğ‘}, onde ğ‘Ã© o nÃº-
mero de itens sugeridos pelo sistema de recomendaÃ§Ã£o. AlÃ©m disso,
existem as informaÃ§Ãµes dos usuÃ¡rios sobre as preferÃªncias de popu-
laridade. A tarefa Ã© explorar essas preferÃªncias para gerar uma lista
de recomendaÃ§Ãµes que aumente a justiÃ§a em relaÃ§Ã£o a popularidade
dos itens.
Para tanto, propÃµe-se uma abordagem de calibraÃ§Ã£o em etapa
de processamento. Na prÃ¡tica, o mÃ©todo utiliza medidas de diver-
gÃªncia na etapa de geraÃ§Ã£o de recomendaÃ§Ãµes para realizar uma
calibraÃ§Ã£o de acordo com diferentes nÃ­veis de popularidade de inte-
resse do usuÃ¡rio. Como resultado, os usuÃ¡rios recebem uma lista
de recomendaÃ§Ãµes prÃ³xima ao seu perfil de interesse em termos
de popularidade. Essa calibraÃ§Ã£o Ã© incorporada ao BPR. A Figura 2
apresenta a estrutura de calibraÃ§Ã£o de popularidade, cujos detalhes
sÃ£o descritos a seguir.
Figura 2: Estrutura de calibraÃ§Ã£o proposta. A calibraÃ§Ã£o por
popularidade Ã© aplicada de forma combinada ao treinamento
do BPR, resultando em uma lista calibrada de recomendaÃ§Ãµes
de acordo com as preferÃªncias do usuÃ¡rio sobre popularidade
e gÃªneros.
3.1
DivisÃ£o de Popularidade
A calibraÃ§Ã£o da lista de recomendaÃ§Ãµes com base na popularidade
dos itens jÃ¡ consumidos pelo usuÃ¡rio Ã© feita por meio de uma divisÃ£o
de popularidade para agrupar os itens com base na quantidade
WebMediaâ€™2024, Juiz de Fora, Brazil
Rodrigo Ferrari de Souza and Marcelo Garcia Manzato
Figura 3: Curva representando a divisÃ£o dos itens em grupos
de popularidade.
de interaÃ§Ãµes. A divisÃ£o de popularidade, introduzida em [2], Ã©
baseada no conceito de cauda longa dos sistemas de recomendaÃ§Ã£o,
conforme pode ser visualizado na Figura 3. A curva foi dividida
em trÃªs partes. O Head (H), com itens representando 20% do total
de interaÃ§Ãµes. A Tail (T) com itens que somam menos de 20%
das interaÃ§Ãµes, e o grupo Mid (M), que contÃ©m itens que nÃ£o sÃ£o
nem Head (H) nem Tail (T). Vale ressaltar que esta divisÃ£o por
percentual foi escolhida com base no princÃ­pio de Pareto [18].
3.2
CalibraÃ§Ã£o
A calibraÃ§Ã£o por popularidade foi uma adaptaÃ§Ã£o da fÃ³rmula pro-
posta por [24]. Seu trabalho pressupÃµe que os itens podem ter mais
de um gÃªnero, o que nÃ£o Ã© vÃ¡lido no contexto de popularidade,
onde um item possui apenas um nÃ­vel de popularidade. EntÃ£o, ao
invÃ©s disso, foram calculadas as somas dos pesos de cada tipo de
popularidade sobre a soma de todos os pesos.
Assim, ğ‘¥(ğ‘¡|ğ‘¢) Ã© definido como a distribuiÃ§Ã£o alvo baseada na
popularidade dos itens com os quais o usuÃ¡rio interagiu no pas-
sado. Na EquaÃ§Ã£o 1 os pesos ğ‘Ÿğ‘¢ğ‘–sÃ£o definidos como a classificaÃ§Ã£o
explÃ­cita ou implÃ­cita que o usuÃ¡rio ğ‘¢deu ao item ğ‘–:
ğ‘¥(ğ‘¡|ğ‘¢) =
Ã
ğ‘–âˆˆğ¼ğ‘¢ğ‘Ÿğ‘¢ğ‘–Â· ğ‘¥(ğ‘¡|ğ‘–)
Ã
ğ‘–âˆˆğ¼ğ‘¢ğ‘Ÿğ‘¢ğ‘–
(1)
onde ğ¼ğ‘¢Ã© o conjunto de itens interagidos pelo usuÃ¡rio ğ‘¢, e ğ‘¥(ğ‘¡|ğ‘–) Ã©
definido como 1 se o item ğ‘–estiver na categoria de popularidade ğ‘¡.
EntÃ£o, para lidar com a distribuiÃ§Ã£o de lista recomendada, a EquaÃ§Ã£o
2 define ğ‘¦(ğ‘¡|ğ‘¢) como:
ğ‘¦(ğ‘¡|ğ‘¢) =
Ã
ğ‘–âˆˆğ‘…âˆ—ğ‘¢ğ‘¤ğ‘(ğ‘¢,ğ‘–) Â· ğ‘¥(ğ‘¡|ğ‘–)
Ã
ğ‘–âˆˆğ‘…âˆ—ğ‘¢ğ‘¤ğ‘(ğ‘¢,ğ‘–)
(2)
Neste caso, usamos os pesos ğ‘¤ğ‘(ğ‘¢,ğ‘–) como a posiÃ§Ã£o de classifi-
caÃ§Ã£o do item ğ‘–na lista reordenada recomendada ğ‘…âˆ—ğ‘¢para o usuÃ¡rio
ğ‘¢.
VÃ¡rias mÃ©tricas avaliam a imparcialidade em sistemas de reco-
mendaÃ§Ã£o [26]. PorÃ©m, nesse caso, utiliza-se a medida de diver-
gÃªncia Kullback-Leibler pelas mesmas razÃµes apontadas por [24] e
exploradas por [9]. O Kullback-Leibler quantifica a desigualdade
no intervalo [0, âˆ], onde 0 significa que ambas as distribuiÃ§Ãµes sÃ£o
quase iguais e valores mais altos indicam injustiÃ§a.
Adicionalmente, Ã© adotada a regularizaÃ§Ã£o proposta por [24],
que definiu ğ›¼= 0.01 como uma variÃ¡vel de regularizaÃ§Ã£o para
evitar divisÃ£o por zero quando ğ‘¦(ğ‘¡|ğ‘¢) vai para zero. Embora exis-
tam outras mÃ©tricas de divergÃªncia, como Hellinger e Person Qui-
Square, propostas por [4] e exploradas por [9], foi utilizada apenas
a Kullback-Leibler devido Ã  sua simplicidade:
ğ·ğ¾ğ¿(ğ‘¥âˆ¥ğ‘¦) =
âˆ‘ï¸
ğ‘¡
ğ‘¥(ğ‘¡|ğ‘¢) Â· ğ‘™ğ‘œğ‘”
ğ‘¥(ğ‘¡|ğ‘¢)
(1 âˆ’ğ›¼) Â· ğ‘¦(ğ‘¡|ğ‘¢) + ğ›¼Â· ğ‘¥(ğ‘¡|ğ‘¢)
(3)
A divergÃªncia de Kullback-Leibler Ã© uma medida que quantifica a
diferenÃ§a entre duas distribuiÃ§Ãµes de probabilidade, neste caso, entre
a distribuiÃ§Ã£o observada ğ‘¥(ğ‘¡|ğ‘¢) e a distribuiÃ§Ã£o de referÃªncia ğ‘¦(ğ‘¡|ğ‘¢).
No contexto da calibraÃ§Ã£o por popularidade, ğ‘¥(ğ‘¡|ğ‘¢) representa a
distribuiÃ§Ã£o empÃ­rica dos itens observados pelo usuÃ¡rioğ‘¢, enquanto
ğ‘¦(ğ‘¡|ğ‘¢) representa uma distribuiÃ§Ã£o de referÃªncia desejada, que Ã©
baseada na popularidade dos itens na base de dados.
3.3
O MÃ©todo BPR
O BPR [20] Ã© uma abordagem eficaz para recomendaÃ§Ã£o de itens
em sistemas de recomendaÃ§Ã£o baseados em feedback implÃ­cito. Ao
modelar as preferÃªncias dos usuÃ¡rios por meio de caracterÃ­sticas
latentes e otimizar a funÃ§Ã£o de perda, o modelo Ã© capaz de aprender
efetivamente as preferÃªncias dos usuÃ¡rios e gerar recomendaÃ§Ãµes
personalizadas, levando em consideraÃ§Ã£o a ordem de preferÃªncia
dos itens.
Mantendo a notaÃ§Ã£o utilizada na seÃ§Ã£o anterior, as letras de inde-
xaÃ§Ã£o especial distinguem usuÃ¡rios e itens: um usuÃ¡rio Ã© indicado
comoğ‘¢e um item Ã© referido comoğ‘–, ğ‘—;ğ‘Ÿğ‘¢ğ‘–refere-se ao feedback explÃ­-
cito ou implÃ­cito de um usuÃ¡rio ğ‘¢para um item ğ‘–. No primeiro caso,
Ã© um nÃºmero inteiro fornecido pelo usuÃ¡rio indicando o quanto
ele gostou do conteÃºdo; no segundo caso, Ã© apenas um booleano
mostrando se o usuÃ¡rio consumiu ou visitou o conteÃºdo ou nÃ£o. A
prediÃ§Ã£o do sistema sobre a preferÃªncia do usuÃ¡rio ğ‘¢para o item ğ‘–
Ã© representada por Ë†ğ‘Ÿğ‘¢ğ‘–, que Ã© um valor de ponto flutuante estimado
pelo algoritmo de recomendaÃ§Ã£o. O conjunto de pares (ğ‘¢,ğ‘–) para
os quais ğ‘Ÿğ‘¢ğ‘–Ã© conhecido Ã© representado por ğ¾= {(ğ‘¢,ğ‘–)|ğ‘Ÿğ‘¢ğ‘–}.
Em um modelo de fatorizaÃ§Ã£o tradicional, cada usuÃ¡rio ğ‘¢Ã© asso-
ciado a um vetor de fatores ğ‘ğ‘¢âˆˆRğ‘“e cada item ğ‘–com um vetor de
fatores ğ‘ğ‘–âˆˆRğ‘“. Uma regra de previsÃ£o seria:
Ë†ğ‘Ÿğ‘¢ğ‘–= ğ‘ğ‘‡
ğ‘¢ğ‘ğ‘–
(1)
(4)
Conjuntos adicionais sÃ£o ğ‘(ğ‘¢), que indica o conjunto de itens
para os quais o usuÃ¡rio ğ‘¢forneceu um feedback implÃ­cito, e ğ‘(ğ‘¢),
que indica o conjunto de itens desconhecidos para o usuÃ¡rio ğ‘¢. Uma
caracterÃ­stica importante desse tipo de feedback Ã© que apenas as
observaÃ§Ãµes positivas sÃ£o conhecidas; os pares usuÃ¡rio-item nÃ£o
observados sÃ£o interpretados como feedback negativo.
O trabalho [20] discute um problema que surge quando um mo-
delo de recomendaÃ§Ã£o de itens Ã© treinado apenas com esses dados
Uma Abordagem em Etapa de Processamento para ReduÃ§Ã£o do ViÃ©s de Popularidade
WebMediaâ€™2024, Juiz de Fora, Brazil
Figura 4: O quadro Ã  esquerda representa os dados observados.
A abordagem cria uma relaÃ§Ã£o par de itens especÃ­fica para o
usuÃ¡rio ğ‘–â‰»ğ‘¢ğ‘—entre dois itens. No lado direito da tabela, o
sinal de mais indica que o usuÃ¡rio ğ‘¢estÃ¡ mais interessado no
item ğ‘–do que no item ğ‘—; o sinal de menos indica que o usuÃ¡rio
prefere o item ğ‘—ao ğ‘–; o ponto de interrogaÃ§Ã£o indica que nÃ£o
se pode inferir nenhuma conclusÃ£o entre os itens.
positivos/negativos. Como as entradas observadas sÃ£o positivas e
as restantes sÃ£o negativas, o modelo serÃ¡ ajustado para fornecer
apenas pontuaÃ§Ãµes positivas para os itens observados. Os elementos
restantes, incluindo aqueles que podem ser de interesse para o usuÃ¡-
rio, serÃ£o classificados pelo modelo como pontuaÃ§Ãµes negativas e
a classificaÃ§Ã£o nÃ£o poderÃ¡ ser otimizada, pois as previsÃµes estarÃ£o
em torno de zero.
Os autores propuseram um mÃ©todo genÃ©rico para aprender o
comportamento do usuÃ¡rio para classificaÃ§Ã£o personalizada [20].
Em vez de treinar o modelo usando apenas os pares usuÃ¡rio-item,
eles tambÃ©m consideraram a ordem relativa entre um par de itens, de
acordo com as preferÃªncias do usuÃ¡rio. Se um item ğ‘–foi visualizado
pelo usuÃ¡rio ğ‘¢e ğ‘—nÃ£o (ğ‘–âˆˆğ‘(ğ‘¢) e ğ‘—âˆˆğ‘(ğ‘¢)), entÃ£o ğ‘–Ã© preferido
a ğ‘—. A Figura 4 mostra um exemplo do mÃ©todo. Quando ğ‘–e ğ‘—sÃ£o
desconhecidos para o usuÃ¡rio, ou equivalentemente, ambos sÃ£o
conhecidos, nenhuma conclusÃ£o sobre sua importÃ¢ncia relativa
para o usuÃ¡rio pode ser inferida.
Para estimar se um usuÃ¡rio prefere um item a outro, [20] propu-
seram uma anÃ¡lise Bayesiana usando uma funÃ§Ã£o de probabilidade
ğ‘ğ‘Ÿğ‘œğ‘(ğ‘–â‰»ğ‘¢ğ‘—|ğ‘¢, Î˜) e a probabilidade anterior para o parÃ¢metro do
modelo ğ‘ğ‘Ÿğ‘œğ‘(Î˜). O critÃ©rio final de otimizaÃ§Ã£o, BPR-Opt, Ã© definido
como:
ğµğ‘ƒğ‘…-ğ‘‚ğ‘ğ‘¡B
âˆ‘ï¸
(ğ‘¢,ğ‘–,ğ‘—)âˆˆğ‘†ğ¾
lnğœ(Ë†ğ‘ ğ‘¢ğ‘–ğ‘—) âˆ’Î›Î˜âˆ¥Î˜âˆ¥2
onde Ë†ğ‘ ğ‘¢ğ‘–ğ‘—B Ë†ğ‘Ÿğ‘¢ğ‘–âˆ’Ë†ğ‘Ÿğ‘¢ğ‘—e ğ‘†ğ¾Ã© o conjunto de triplas (ğ‘¢,ğ‘–, ğ‘—) onde ğ‘–
estÃ¡ em ğ‘(ğ‘¢) e ğ‘—nÃ£o estÃ¡. O sÃ­mbolo Î˜ representa os parÃ¢metros
do modelo, Î›Î˜ Ã© o conjunto de constantes de regularizaÃ§Ã£o, e ğœÃ© a
funÃ§Ã£o logÃ­stica definida como ğœ(ğ‘¥) =
1+ğ‘’âˆ’ğ‘¥.
Os autores tambÃ©m propuseram uma variaÃ§Ã£o na tÃ©cnica de
descida de gradiente estocÃ¡stico, denominada LearnBPR, que amos-
tra aleatoriamente de ğ‘†ğ¾para ajustar Î˜. O Algoritmo 1 mostra
uma visÃ£o geral do mÃ©todo de aprendizagem, onde ğ›¼Ã© a taxa de
aprendizado.
No presente estudo, definimos a abordagem BPR para considerar
a regra de prediÃ§Ã£o Ë†ğ‘Ÿğ‘¢ğ‘–do modelo de fatorizaÃ§Ã£o simples definido
na EquaÃ§Ã£o 4. Portanto, aplicar a EquaÃ§Ã£o 4 em Ë†ğ‘ ğ‘¢ğ‘–ğ‘—resulta em Î˜ =
Algorithm 1: Aprendizado via LearnBPR.
Input: ğ·ğ¾
Output: ParÃ¢metros ajustados Î˜
1 Inicializar Î˜ com valores aleatÃ³rios
2 for cont = 1,...,#IteraÃ§Ãµes do
obtenha (ğ‘¢,ğ‘–, ğ‘—) a partir de ğ‘†ğ¾
Ë†ğ‘ ğ‘¢ğ‘–ğ‘—â†Ë†ğ‘Ÿğ‘¢ğ‘–âˆ’Ë†ğ‘Ÿğ‘¢ğ‘—
Î˜ â†Î˜ + ğ›¼

ğ‘’âˆ’Ë†ğ‘ ğ‘¢ğ‘–ğ‘—
1+ğ‘’âˆ’Ë†ğ‘ ğ‘¢ğ‘–ğ‘—. ğœ•
ğœ•Î˜ Ë†ğ‘ ğ‘¢ğ‘–ğ‘—âˆ’Î›Î˜Î˜

6 end
{ğ‘ğ‘¢,ğ‘ğ‘–,ğ‘ğ‘—}, que devem ser aprendidos. Calculamos as derivadas
parciais em relaÃ§Ã£o a Ë†ğ‘ ğ‘¢ğ‘–ğ‘—:
ğœ•
ğœ•Î˜ Ë†ğ‘ ğ‘¢ğ‘–ğ‘—=
ï£±ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´ï£³
ğ‘ğ‘–âˆ’ğ‘ğ‘—
quando Î˜ = ğ‘ğ‘¢
ğ‘ğ‘¢
quando Î˜ = ğ‘ğ‘–
âˆ’ğ‘ğ‘¢
quando Î˜ = ğ‘ğ‘—
caso contrÃ¡rio
Esses gradientes sÃ£o entÃ£o usados para atualizar os fatores de
usuÃ¡rio e item em direÃ§Ã£o ao mÃ­nimo da funÃ§Ã£o de perda, iterativa-
mente, atÃ© que a convergÃªncia seja alcanÃ§ada ou um nÃºmero fixo
de iteraÃ§Ãµes seja concluÃ­do. Desse modo, o SGD permite ajustar
os fatores de usuÃ¡rio e item de forma a maximizar a diferenÃ§a en-
tre as pontuaÃ§Ãµes dos itens positivos e negativos, resultando em
recomendaÃ§Ãµes mais precisas e personalizadas.
3.4
BPR com CalibraÃ§Ã£o por Popularidade
Com o objetivo de combinar um modelo em etapa de processa-
mento com uma forma de calibraÃ§Ã£o de popularidade para trazer
recomendaÃ§Ãµes que reduzam o viÃ©s de popularidade no sistema, a
estratÃ©gia adotada foi alterar o algoritmo de aprendizado LearnBPR
(Algoritmo 1). Assim, pode-se combinar o BPR com a calibraÃ§Ã£o
por popularidade, acrescentando no algoritmo a divergÃªncia de
Kullback-Leibler implementada na calibraÃ§Ã£o de popularidade.
Essa combinaÃ§Ã£o pode possibilitar uma maior justiÃ§a nas reco-
mendaÃ§Ãµes em termos de popularidade, jÃ¡ que esse aspecto seria
levado em conta na funÃ§Ã£o de perda do BPR. A alteraÃ§Ã£o Ã© realizada
na linha 5 do Algoritmo 1 somente quando Î˜ = ğ‘ğ‘¢:
ğ‘ğ‘¢â†ğ‘ğ‘¢+ ğ›¼

ğ‘’âˆ’Ë†ğ‘ ğ‘¢ğ‘–ğ‘—
1 + ğ‘’âˆ’Ë†ğ‘ ğ‘¢ğ‘–ğ‘—.(ğ‘ğ‘–âˆ’ğ‘ğ‘—)
+ ğœ†

1 âˆ’ğ·ğ¾ğ¿(ğ‘¥âˆ¥ğ‘¦)
ğ·ğ¾ğ¿ğ‘£ğ‘œğ‘–ğ‘‘

âˆ’Î›ğ‘ğ‘¢ğ‘ğ‘¢

(5)
onde ğœ†Ã© utilizado como coeficiente do impacto que a divergÃªncia
terÃ¡ no sistema, e ğ·ğ¾ğ¿ğ‘£ğ‘œğ‘–ğ‘‘Ã© definido como:
ğ·ğ¾ğ¿ğ‘£ğ‘œğ‘–ğ‘‘=
âˆ‘ï¸
ğ‘¡
ğ‘¥(ğ‘¡|ğ‘¢) Â· ğ‘™ğ‘œğ‘”ğ‘¥(ğ‘¡|ğ‘¢)
ğ›¼Â· ğ‘¥(ğ‘¡|ğ‘¢)
(6)
A razÃ£o para dividir a divergÃªncia ğ·ğ¾ğ¿(ğ‘¥,ğ‘¦) por ğ·ğ¾ğ¿ğ‘£ğ‘œğ‘–ğ‘‘Ã© nor-
malizar o valor da divergÃªncia, deixando o valor ajustado para uma
escala especÃ­fica. Essa normalizaÃ§Ã£o pode ser Ãºtil para realizar a
calibraÃ§Ã£o por popularidade entre diferentes usuÃ¡rios ou grupos,
WebMediaâ€™2024, Juiz de Fora, Brazil
Rodrigo Ferrari de Souza and Marcelo Garcia Manzato
independentemente do nÃºmero total de itens ou da escala de popu-
laridade na base de dados, possibilitando a aplicaÃ§Ã£o em diferentes
contextos.
Ao considerar nÃ£o apenas as preferÃªncias individuais dos usuÃ¡-
rios, mas tambÃ©m a popularidade relativa dos itens, a abordagem
modificada pode levar a recomendaÃ§Ãµes mais relevantes e persona-
lizadas. Isso pode resultar em uma melhor experiÃªncia do usuÃ¡rio e
maior satisfaÃ§Ã£o com o sistema de recomendaÃ§Ã£o.
AVALIAÃ‡ÃƒO
A execuÃ§Ã£o do experimento foi realizada trÃªs vezes em dois conjun-
tos de dados do domÃ­nio de filmes para garantir a confiabilidade dos
resultados. A repetiÃ§Ã£o dos testes ajuda a mitigar o impacto de vari-
aÃ§Ãµes aleatÃ³rias, assegurando que a mÃ©dia dos valores obtidos seja
representativa do desempenho do modelo. O t-test de Student foi
escolhido para anÃ¡lise por ser amplamente utilizado na comparaÃ§Ã£o
de mÃ©dias entre dois grupos, especialmente com amostras pequenas
ou moderadas [15], onde as variÃ¡veis seguem uma distribuiÃ§Ã£o apro-
ximadamente normal. Como as bases de dados utilizadas possuem
dados contÃ­nuos e distribuÃ­dos de forma aproximada Ã  normal, este
teste Ã© adequado para a anÃ¡lise estatÃ­stica. A Tabela 1 resume as
informaÃ§Ãµes dos conjuntos de dados utilizados.
â€¢ Yahoo Movies1: Este conjunto de dados Ã© uma classificaÃ§Ã£o
de filmes do usuÃ¡rio, onde o usuÃ¡rio atribui notas de um a
cinco aos filmes que assistiu. Na etapa de prÃ©-processamento,
foram removidos apenas filmes sem gÃªnero nos metadados.
Em vez de binarizar a classificaÃ§Ã£o como feito por [24], foi
utilizado o feedback explÃ­cito como o peso ğ‘Ÿğ‘¢ğ‘–na EquaÃ§Ã£o 1.
â€¢ MovieLens-20M2: Neste conjunto de dados, semelhante
a [24] e em contraste com o conjunto de dados do Yahoo
Movies, foi feita a binarizaÃ§Ã£o das classificaÃ§Ãµes retendo as
interaÃ§Ãµes onde a classificaÃ§Ã£o era superior a 4. AlÃ©m disso,
devido a limitaÃ§Ãµes de hardware, o tamanho do conjunto
de dados foi reduzido, removendo filmes com menos de dez
interaÃ§Ãµes e usuÃ¡rios com menos de 180 filmes.
Tabela 1: EstatÃ­sticas dos conjuntos de dados apÃ³s realizaÃ§Ã£o
do prÃ©-processamento.
Conjunto de dados
# UsuÃ¡rios
# InteraÃ§Ãµes
# Itens
Yahoo Movies
7,642
211,231
11,916
MovieLens 20M
12,603
3,984,599
10,417
O experimento foi executado trÃªs vezes em cada conjunto de
dados para obter a mÃ©dia dos valores gerados pelas mÃ©tricas e
garantir a estabilidade dos resultados. Os conjuntos de dados de
teste e treinamento foram escolhidos dividindo aleatoriamente o
conjunto de dados em 70/30% de interaÃ§Ãµes, seguindo respectiva-
mente [2, 9]. O desempenho da abordagem foi comparado com os
seguintes trabalhos do estado da arte:
(1) BPR: Proposta em [20], Ã© um algoritmo de recomendaÃ§Ã£o
projetado para lidar com dados de feedback implÃ­cito, onde
as interaÃ§Ãµes entre usuÃ¡rios e itens sÃ£o representadas como
1https://webscope.sandbox.yahoo.com/
2https://grouplens.org/datasets/movielens/20m/
preferÃªncias binÃ¡rias. Para os trÃªs conjuntos de dados, foi
aplicado o batch = 1024.
(2) PairWise: Proposto por [3], este mÃ©todo atua como uma
etapa de processamento para reduÃ§Ã£o do impacto do viÃ©s de
popularidade. Para o conjunto de dados do Yahoo Movies,
foram aplicados ğ‘’ğ‘ğ‘œğ‘â„= 100, ğ‘ğ‘ğ‘¡ğ‘â„= 1024 e escolhido o
melhor ğ›¼variando no intervalo [0, 1]. Para o conjunto de
dados MovieLens, foram utilizados ğ‘ğ‘ğ‘¡ğ‘â„= 2048 e ğ‘’ğ‘ğ‘œğ‘â„=
20. A implementaÃ§Ã£o seguiu aquela feita pelos autores3.
MÃ©tricas. Em nossos experimentos, avaliamos os efeitos da ca-
libraÃ§Ã£o em termos de precisÃ£o, justiÃ§a e viÃ©s de popularidade,
conforme detalhado a seguir:
(1) PrecisÃ£o e Qualidade: usamos as mÃ©tricas Mean Reciprocal
Rank (MRR) e Mean Average Precision (MAP) para medir
a qualidade da classificaÃ§Ã£o do item na lista reclassificada.
MAP e MRR variam no intervalo [0, 1] onde valores mais
altos sÃ£o melhores.
(2) JustiÃ§a: utilizamos uma mÃ©trica proposta por [9], denomi-
nada Mean Rank Miscalibration (MRMC), que cobre o in-
tervalo [0, 1], onde valores mais baixos sÃ£o melhores.
Inicialmente, ela foi usada para calcular a justiÃ§a em gÃªne-
ros na lista de recomendaÃ§Ãµes, mas neste trabalho ela foi
adaptada para calcular o erro de calibraÃ§Ã£o de popularidade.
Embora nossa proposta visa reduzir a injustiÃ§a em termos
de popularidade, nÃ³s tambÃ©m medimos a justiÃ§a de gÃªneros
neste trabalho. Para isso, usamos a mÃ©dia harmÃ´nica F1 entre
MRMC de gÃªneros e popularidade, onde valores mais altos
sÃ£o melhores:
ğ¹1 = 2 (1 âˆ’ğ‘€ğ‘…ğ‘€ğ¶ğºğ‘’ğ‘›ğ‘’ğ‘Ÿğ‘œ) âˆ—(1 âˆ’ğ‘€ğ‘…ğ‘€ğ¶ğ‘ƒğ‘œğ‘)
(1 âˆ’ğ‘€ğ‘…ğ‘€ğ¶ğºğ‘’ğ‘›ğ‘’ğ‘Ÿğ‘œ) + (1 âˆ’ğ‘€ğ‘…ğ‘€ğ¶ğ‘ƒğ‘œğ‘)
(7)
(3) ViÃ©s de popularidade: usamos as mÃ©tricas de cobertura
de cauda longa (LTC) [2] e popularidade mÃ©dia do grupo
(Î”GAP) [2] para medir o viÃ©s de popularidade. A mÃ©trica LTC
indica a fraÃ§Ã£o de itens que os usuÃ¡rios recebem nas listas de
recomendaÃ§Ã£o e varia no intervalo [0, 1], onde 0 significa que
todos os itens recomendados sÃ£o os mais populares e 1 signi-
fica que todos os itens recomendados a um usuÃ¡rio estÃ£o nas
categorias menos populares. Assim, quanto mais prÃ³ximo
de 1, mais diversificado serÃ¡ o conteÃºdo recomendado
[2]. O Î”GAP varia no intervalo [âˆ’1, 1], onde valores negati-
vos significam que as recomendaÃ§Ãµes sÃ£o menos populares
do que o esperado segundo as preferÃªncias dos usuÃ¡rios, e
valores positivos significam que as recomendaÃ§Ãµes sÃ£o mais
populares do que o esperado. TambÃ©m adotamos trÃªs divi-
sÃµes de grupos de usuÃ¡rios, com base em [2] para o Î”GAP:
BlockBuster (BB) cujo consumo dos usuÃ¡rios Ã© de pelo
menos 50% dos itens mais populares, Nicho (N) onde o con-
sumo dos usuÃ¡rios Ã© de pelo menos 50% dos itens de menor
popularidade e Diverso (D) cujas preferÃªncias dos usuÃ¡rios
divergem dos outros dois grupos. Finalmente, como os valo-
res Ã³timos de Î”ğºğ´ğ‘ƒdevem ser prÃ³ximos de zero, propomos
neste artigo a utilizaÃ§Ã£o do Root Mean Squared Error (RMSE)
entre os trÃªs grupos de usuÃ¡rios, onde valores mais baixos
sÃ£o melhores:
3https://github.com/biasinrecsys/wsdm2021
Uma Abordagem em Etapa de Processamento para ReduÃ§Ã£o do ViÃ©s de Popularidade
WebMediaâ€™2024, Juiz de Fora, Brazil
ğ‘…ğ‘€ğ‘†ğ¸=
âˆšï¸ƒ
Î”ğºğ´ğ‘ƒ2
ğµğµ+ Î”ğºğ´ğ‘ƒ2
ğ‘+ Î”ğºğ´ğ‘ƒ2
ğ·
(8)
RESULTADOS
5.1
Yahoo Movies
A Tabela 2 apresenta os resultados obtidos para o conjunto de
dados Yahoo Movies. Analisando apenas a precisÃ£o dos modelos
pela mÃ©trica MAP, notamos que a abordagem PairWise [3] atingiu
o maior valor de MAP. No entanto, esta conquista significa que
os itens nÃ£o sÃ£o muito diversos entre si, como mostram os seus
resultados relativos a LTC, F1 e RMSE.
Em relaÃ§Ã£o Ã  justiÃ§a dos gÃªneros atravÃ©s do MRMC de gÃªneros,
a Tabela 2 indica que a proposta de calibraÃ§Ã£o combinada com o BPR
produziu o melhor resultado, indicando que foi capaz de fornecer
itens mais prÃ³ximos do perfil em termos de gÃªnero. O mesmo foi
verificado em relaÃ§Ã£o Ã  justiÃ§a de popularidade, com a proposta
tendo o melhor resultado do MRMC Pop.
Em termos de cobertura de cauda longa, a tabela indica que
o modelo mais eficaz para recomendar itens diversos foi o BPR. O
PairWise com pontuaÃ§Ãµes mais altas no MAP obteve valores mais
baixos para o LTC. Em relaÃ§Ã£o Ã  mÃ©trica F1, Ã© possÃ­vel observar que
a proposta conseguiu alcanÃ§ar o melhor resultado, indicando que a
abordagem de calibraÃ§Ã£o foi capaz de calibrar recomendaÃ§Ãµes de
acordo com gÃªneros e popularidade. Este aspecto Ã© ainda validado
ao analisar a mÃ©trica RMSE, onde a mesma abordagem obteve
menor erro com a calibraÃ§Ã£o, indicando que ela aborda os pontos
de justiÃ§a mencionados e reduz o viÃ©s de popularidade do sistema.
Os resultados relatados na Tabela 2 mostram que a abordagem
de calibraÃ§Ã£o foi capaz de equilibrar recomendaÃ§Ãµes de acordo com
gÃªneros e popularidade, em oposiÃ§Ã£o aos outros trabalhos, que sÃ£o
mais adequados para um Ãºnico aspecto, como precisÃ£o, gÃªneros
ou popularidade. AlÃ©m disso, os resultados mostram a importÃ¢ncia
de adotar mÃ©tricas alÃ©m da precisÃ£o na anÃ¡lise de algoritmos de
recomendaÃ§Ã£o. Reconhece-se a alta precisÃ£o do PairWise, conforme
indicado pela mÃ©trica MAP. No entanto, os usuÃ¡rios que preferem
itens de nicho, diversos e impopulares sÃ£o afetados por recomenda-
Ã§Ãµes injustas e tendenciosas produzidas por essas abordagens.
5.2
MovieLens 20M
A Tabela 2 apresenta os resultados obtidos para o conjunto de dados
MovieLens 20M. Analisando a precisÃ£o, assim como na base de
dados anterior, o PairWise [3] superou as outras abordagens. No
entanto, os resultados tambÃ©m indicam que estas abordagens devol-
vem recomendaÃ§Ãµes injustas em termos de gÃªnero e popularidade,
e carecem de diversidade.
Em relaÃ§Ã£o Ã  justiÃ§a dos gÃªneros e Ã  justiÃ§a de popularidade,
a abordagem de calibraÃ§Ã£o proposta obteve os melhores resultados,
fato confirmado pela mÃ©trica F1. Em relaÃ§Ã£o Ã  cobertura de cauda
longa, o BPR obteve o melhor resultado entre todas as aborda-
gens. AlÃ©m disso, o PairWise [3] alcanÃ§ou um valor baixo para essa
mÃ©trica, apesar de ter uma alta precisÃ£o.
Com relaÃ§Ã£o ao F1, pode-se observar que a proposta obteve os
melhores valores, destacando seu alto desempenho em termos de
justiÃ§a nos gÃªneros e popularidade. Ademais, a proposta tambÃ©m
obteve o melhor resultado em RMSE, indicando que o sistema
reduziu com sucesso o viÃ©s de popularidade para diferentes grupos
de usuÃ¡rios.
A Tabela 2 reporta resultados semelhantes aos do conjunto de
dados Yahoo Movies, indicando que a proposta melhorou a justiÃ§a
dos gÃªneros e a popularidade em ambos os conjuntos de dados. Em-
bora a abordagem de calibraÃ§Ã£o proposta nÃ£o tenha alcanÃ§ado alta
precisÃ£o, obteve o menor erro de calibraÃ§Ã£o de gÃªnero e de popula-
ridade, o que significa que o modelo fornece recomendaÃ§Ãµes que
respeitam o perfil do usuÃ¡rio tanto no gÃªnero quanto no consumo
de popularidade.
CONCLUSÃƒO
O objetivo do BPR Ã© aprender representaÃ§Ãµes latentes para usuÃ¡rios
e itens que capturem suas preferÃªncias individuais. O procedimento
de aprendizado do BPR envolve a otimizaÃ§Ã£o de uma funÃ§Ã£o de
perda que visa maximizar a ordenaÃ§Ã£o correta dos pares de itens
positivos e negativos para cada usuÃ¡rio. Isso Ã© feito por meio de
gradiente descendente estocÃ¡stico, onde os gradientes da funÃ§Ã£o de
perda sÃ£o calculados para atualizar os vetores latentes dos usuÃ¡rios
e dos itens.
A modificaÃ§Ã£o proposta, que combina o BPR com a calibraÃ§Ã£o
por popularidade, visa melhorar a justiÃ§a nas recomendaÃ§Ãµes, con-
siderando nÃ£o apenas as preferÃªncias individuais dos usuÃ¡rios, mas
tambÃ©m a popularidade relativa dos itens. Isso Ã© alcanÃ§ado incor-
porando a divergÃªncia de Kullback-Leibler na funÃ§Ã£o de perda do
BPR, levando a recomendaÃ§Ãµes mais relevantes e personalizadas. Os
experimentos realizados em dois conjuntos de dados mostram que a
abordagem modificada obtÃ©m resultados comparÃ¡veis ou melhores
em relaÃ§Ã£o aos mÃ©todos do estado da arte, tanto em mÃ©tricas de
classificaÃ§Ã£o quanto em mÃ©tricas de popularidade e justiÃ§a.
No entanto, Ã© importante ressaltar que a abordagem proposta
ainda pode ser aprimorada em vÃ¡rios aspectos. Por exemplo, a esco-
lha dos parÃ¢metros do modelo, como o tamanho do lote e o nÃºmero
de Ã©pocas, pode afetar significativamente o desempenho do sistema.
AlÃ©m disso, a implementaÃ§Ã£o de tÃ©cnicas adicionais de regulariza-
Ã§Ã£o ou otimizaÃ§Ã£o pode ajudar a evitar o sobreajuste e melhorar a
convergÃªncia do modelo. HÃ¡ tambÃ©m a possibilidade de combinar
tÃ©cnicas de reduÃ§Ã£o do viÃ©s de popularidade com os sistemas con-
versacionais [28]. Futuras pesquisas podem explorar essas direÃ§Ãµes
para desenvolver ainda mais a abordagem proposta e melhorar sua
eficÃ¡cia em uma variedade de cenÃ¡rios de recomendaÃ§Ã£o.
AGRADECIMENTOS
Os autores gostariam de agradecer o apoio financeiro da FAPESP,
processo nÃºmero 2022/07016-9, e CNPq.
REFERÃŠNCIAS
[1] Himan Abdollahpouri, Masoud Mansoury, Robin Burke, and Bamshad Mo-
basher. 2020. The connection between popularity bias, calibration, and fair-
ness in recommendation. In Fourteenth ACM conference on recommender sys-
tems. Association for Computing Machinery, New York, NY, USA, 726â€“731.
https://doi.org/10.1145/3383313.3418487
[2] Himan Abdollahpouri, Masoud Mansoury, Robin Burke, Bamshad Mobasher,
and Edward C. Malthouse. 2021. User-centered Evaluation of Popularity Bias
in Recommender Systems. In Proceedings of the 29th ACM Conference on User
Modeling, Adaptation and Personalization, UMAP 2021, Utrecht, The Netherlands,
June, 21-25, 2021, Judith Masthoff, Eelco Herder, Nava Tintarev, and Marko Tkalcic
(Eds.). ACM, 119â€“129. https://doi.org/10.1145/3450613.3456821
WebMediaâ€™2024, Juiz de Fora, Brazil
Rodrigo Ferrari de Souza and Marcelo Garcia Manzato
Tabela 2: ComparaÃ§Ã£o da abordagem proposta com os outros trabalhos nos conjuntos de dados Yahoo Movies e MovieLens 20M.
O sÃ­mbolo â–²significa que a proposta teve um ganho significativo com relaÃ§Ã£o aos outros trabalhos, com um p-value < 0.05
usando o t-test de Student; o sÃ­mbolo â€¢ significa que nÃ£o houve um ganho ou perda significativo; e o sÃ­mbolo â–¼indica que o
outro trabalho Ã© estatisticamente melhor que a proposta. Cada par de sÃ­mbolos se refere ao BPR e ao PairWise, respectivamente.
Yahoo Movies
Algoritmo
LTC
MRMC GÃªneros
MRMC Pop.
F1 Score
MRR
MAP
Î”ğºğ´ğ‘ƒğµğµ
Î”ğºğ´ğ‘ƒğ‘
Î”ğºğ´ğ‘ƒğ·
RMSE
BPR
0.409
0.629
0.687
0.340
0.002
0.001
-0.991
-0.881
-0.978
0.549
PairWise
0.140
0.696
0.661
0.321
0.012
0.038
-0.680
3.105
0.043
1.060
BPR Modificado
0.317 â–¼â–²
0.589
0.496
0.444 â–²â–²
0.012 â–²â€¢
0.004 â–²â–¼
-0.934
-0.142
-0.835
0.420 â–²â–²
MovieLens 20M
Algoritmo
LTC
MRMC GÃªneros
MRMC Pop.
F1 Score
MRR
MAP
Î”ğºğ´ğ‘ƒğµğµ
Î”ğºğ´ğ‘ƒğ‘
Î”ğºğ´ğ‘ƒğ·
RMSE
BPR
0.513
0.459
0.409
0.565
0.001
0.001
-0.912
-0.340
-0.790
0.419
PairWise
0.110
0.554
0.501
0.452
0.776
0.583
-0.997
-0.997
-0.996
0.575
BPR Modificado
0.464 â–¼â–²
0.453
0.330
0.596 â–²â–²
0.002 â–²â–¼
0.001 â€¢ â–¼
-0.865
-0.060
-0.693
0.370 â–²â–²
[3] Ludovico Boratto, Gianni Fenu, and Mirko Marras. 2021. Connecting user and
item perspectives in popularity debiasing for collaborative recommendation.
Information Processing & Management 58, 1 (2021), 102387.
[4] Sung-Hyuk Cha. 2007. Comprehensive survey on distance/similarity measures
between probability density functions. City 1, 2 (2007), 1.
[5] Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan
He. 2023. Bias and debias in recommender system: A survey and future directions.
ACM Transactions on Information Systems 41, 3 (2023), 1â€“39.
[6] Xiao Chen, Wenqi Fan, Jingfan Chen, Haochen Liu, Zitao Liu, Zhaoxiang Zhang,
and Qing Li. 2023. Fairly adaptive negative sampling for recommendations. In
Proceedings of the ACM Web Conference 2023. 3723â€“3733.
[7] Zhihong Chen, Jiawei Wu, Chenliang Li, Jingxu Chen, Rong Xiao, and Binqiang
Zhao. 2022. Co-training disentangled domain adaptation network for leveraging
popularity bias in recommenders. In Proceedings of the 45th International ACM
SIGIR Conference on Research and Development in Information Retrieval. 60â€“69.
[8] Diego CorrÃªa da Silva and Frederico AraÃºjo DurÃ£o. 2023. Introducing a framework
and a decision protocol to calibrated recommender systems. Applied Intelligence
(2023), 1â€“29.
[9] Diego CorrÃªa da Silva, Marcelo Garcia Manzato, and Frederico AraÃºjo DurÃ£o. 2021.
Exploiting personalized calibration and metrics for fairness recommendation.
Expert Systems with Applications 181 (2021), 115112.
[10] Yashar Deldjoo, Dietmar Jannach, Alejandro Bellogin, Alessandro Difonzo, and
Dario Zanzonelli. 2023. Fairness in recommender systems: research landscape
and future directions. User Modeling and User-Adapted Interaction (2023), 1â€“50.
[11] Michael FÃ¤rber, Melissa Coutinho, and Shuzhou Yuan. 2023. Biases in scholarly
recommender systems: impact, prevalence, and mitigation. Scientometrics 128, 5
(2023), 2703â€“2736.
[12] Alireza Gharahighehi, Celine Vens, and Konstantinos Pliakos. 2021. Fair multi-
stakeholder news recommender system with hypergraph ranking. Information
Processing & Management 58, 5 (2021), 102663.
[13] Ruben Interian, RuslÃ¡n G. Marzo, Isela Mendoza, and Celso C Ribeiro. 2023.
Network polarization, filter bubbles, and echo chambers: an annotated review
of measures and reduction methods. International Transactions in Operational
Research 30, 6 (2023), 3122â€“3158.
[14] Faisal Kamiran and Toon Calders. 2012. Data preprocessing techniques for
classification without discrimination. Knowledge and information systems 33, 1
(2012), 1â€“33.
[15] Tae Kyun Kim. 2015. T test as a parametric statistic. Korean journal of anesthesio-
logy 68, 6 (2015), 540â€“546.
[16] Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. 2018.
Variational autoencoders for collaborative filtering. In Proceedings of the 2018
world wide web conference. 689â€“698.
[17] Haifeng Liu, Nan Zhao, Xiaokun Zhang, Hongfei Lin, Liang Yang, Bo Xu, Yuan
Lin, and Wenqi Fan. 2022. Dual constraints and adversarial learning for fair
recommenders. Knowledge-Based Systems 239 (2022), 108058.
[18] MEJ Newman. 2005. Power laws, Pareto distributions and Zipf's law. Contempo-
rary Physics 46, 5 (sep 2005), 323â€“351. https://doi.org/10.1080/00107510500052444
[19] Evaggelia Pitoura, Kostas Stefanidis, and Georgia Koutrika. 2022. Fairness in
rankings and recommendations: an overview. The VLDB Journal (2022), 1â€“28.
[20] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv preprint
arXiv:1205.2618 (2012).
[21] Wondo Rhee, Sung Min Cho, and Bongwon Suh. 2022. Countering Popularity
Bias by Regularizing Score Differences. In Proceedings of the 16th ACM Conference
on Recommender Systems. 145â€“155.
[22] Yuji Roh, Kangwook Lee, Steven Whang, and Changho Suh. 2021. Sample se-
lection for fair and robust training. Advances in Neural Information Processing
Systems 34 (2021), 815â€“827.
[23] Andre Sacilotti., Rodrigo Souza., and Marcelo G. Manzato. 2023. Counteracting
Popularity-Bias and Improving Diversity Through Calibrated Recommendations.
In Proceedings of the 25th International Conference on Enterprise Information
Systems - Volume 1: ICEIS. INSTICC, SciTePress, 709â€“720.
https://doi.org/10.
5220/0011846000003467
[24] Harald Steck. 2018. Calibrated recommendations. In Proceedings of the 12th ACM
conference on recommender systems. 154â€“162.
[25] Amit Sultan, Avi Segal, Guy Shani, and Yaâ€™akov Gal. 2022. Addressing Popularity
Bias in Citizen Science. In Proceedings of the 2022 ACM Conference on Information
Technology for Social Good. 17â€“23.
[26] Sahil Verma, Ruoyuan Gao, and Chirag Shah. 2020. Facets of fairness in search
and recommendation. In Bias and Social Aspects in Search and Recommendation:
First International Workshop, BIAS 2020, Lisbon, Portugal, April 14, Proceedings 1.
Springer, 1â€“11.
[27] Lili Wang, Sunit Mistry, Abdulkadir Abdulahi Hasan, Abdiaziz Omar Hassan,
Yousuf Islam, and Frimpong Atta Junior Osei. 2023. Implementation of a Colla-
borative Recommendation System Based on Multi-Clustering. Mathematics 11, 6
(2023), 1346.
[28] Xi Wang, Hossein A Rahmani, Jiqun Liu, and Emine Yilmaz. 2023. Improving
Conversational Recommendation Systems via Bias Analysis and Language-Model-
Enhanced Data Augmentation. arXiv preprint arXiv:2310.16738 (2023).
[29] Tianxin Wei, Fuli Feng, Jiawei Chen, Ziwei Wu, Jinfeng Yi, and Xiangnan He.
2021. Model-agnostic counterfactual reasoning for eliminating popularity bias
in recommender system. In Proceedings of the 27th ACM SIGKDD Conference on
Knowledge Discovery & Data Mining. 1791â€“1800.
[30] Meike Zehlike and Carlos Castillo. 2020. Reducing disparate exposure in ranking:
A learning to rank approach. In Proceedings of the web conference 2020. 2849â€“2855.
[31] Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui
Ling, and Yongdong Zhang. 2021. Causal intervention for leveraging popularity
bias in recommendation. In Proceedings of the 44th International ACM SIGIR
Conference on Research and Development in Information Retrieval. 11â€“20.