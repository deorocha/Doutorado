EstratÃ©gias de Undersampling para ReduÃ§Ã£o de ViÃ©s em
ClassificaÃ§Ã£o de Texto Baseada em Transformers
Guilherme Fonseca
guilhermefonseca8426@aluno.ufsj.edu.br
UFSJ
Minas Gerais, Brazil
Gabriel Prenassi
prenassigabriel@aluno.ufsj.edu.br
UFSJ
Minas Gerais, Brazil
Washington Cunha
washingtoncunha@dcc.ufmg.br
UFMG
Minas Gerais, Brazil
Marcos AndrÃ© GonÃ§alves
mgoncalv@dcc.ufmg.br
UFMG
Minas Gerais, Brazil
Leonardo Rocha
lcrocha@ufsj.edu.br
UFSJ
Minas Gerais, Brazil
WebMediaâ€™2024, Juiz de Fora, Brazil
Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos AndrÃ© GonÃ§alves, & Leonardo Rocha
considerÃ¡vel para melhorias, principalmente em bases de dados
que possuem um elevado grau de desbalanceamento (razÃ£o entre
nÃºmero de documentos da classe majoritÃ¡ria e o nÃºmero de docu-
mentos da classe minoritÃ¡ria superior a 5).
Existem duas principais abordagens utilizadas para lidar com
o desbalanceamento de dados. O oversampling consiste em criar
novas amostras (geralmente sintÃ©ticas) da classe minoritÃ¡ria, para
igualÃ¡-la em termos de instÃ¢ncias Ã  classe majoritÃ¡ria [15]. Essa
abordagem incorre em um aumento significativo no tempo de ger-
aÃ§Ã£o dos modelos, uma vez que aumenta-se o total de instÃ¢ncias a
serem consideradas no aprendizado. Mais ainda, a geraÃ§Ã£o sintÃ©tica
de novos dados, principalmente textuais, pode ser nÃ£o trivial [12].
A abordagem alternativa para enfrentar o desbalanceamento Ã© o
undersampling (US), foco do presente trabalho, que sÃ£o tÃ©cnicas que
reduzem instÃ¢ncias da classe majoritÃ¡ria para equilibrar as classes.
AtÃ© onde sabemos, nÃ£o existem estudos na literatura que abordam
como os mÃ©todos de undersampling interagem com os algoritmos
de CAT do estado da arte baseados em Transformers. Assim, nossa
segunda pergunta de pesquisa Ã© PP2: MÃ©todos de undersampling,
aplicados juntamente com classificadores baseados em Transformers,
sÃ£o capazes de reduzir o viÃ©s dos modelos de classificaÃ§Ã£o? Qual o
impacto dessa combinaÃ§Ã£o na efetividade do modelo?
Para responder a PP2, primeiramente realizamos uma revisÃ£o
sistemÃ¡tica sobre os principais mÃ©todos de undersampling propos-
tos na literatura. Identificamos e implementamos 14 mÃ©todos de
undersampling que estÃ£o entre os mais utilizados. Apesar de terem
fins diferentes, as Ã¡reas de seleÃ§Ã£o de instÃ¢ncias (SI) [8] e undersam-
pling sÃ£o bastante relacionadas, pois ambas tratam de tÃ©cnicas que
visam selecionar um subconjunto de dados representativos â€“ o que
as difere sÃ£o os objetivos da reduÃ§Ã£o. Nesse sentido, adaptamos uma
estratÃ©gia de SI, que Ã© considerada estado da arte, para o cenÃ¡rio de
undersampling, o E2SC [6]. Por fim, propomos duas novas estratÃ©-
gias de undersampling, que sÃ£o contribuiÃ§Ãµes desse trabalho: (1) a
UBR (Undersampling Baseado em RedundÃ¢ncia), que se concentra
em remover instÃ¢ncias da classe majoritÃ¡ria consideradas redun-
dantes (muito similares Ã  outras instÃ¢ncias); e (2) E2SC-RL, uma vari-
aÃ§Ã£o do mÃ©todo de SI E2SC que realiza o cÃ¡lculo das probabilidades
das instÃ¢ncias serem removidas por meio de RegressÃ£o LogÃ­stica.
Investigamos o desempenho das 17 tÃ©cnicas de undersampling
em conjunto com o RoBERTa, classificador baseado em Transform-
ers considerado estado da arte em anÃ¡lise de sentimentos [26]. De
fato, benchmarks recentes [10, 26] demonstraram que as diferenÃ§as
entre as novas versÃµes desses Transformers (incluindo RoBERTa,
BERT, DistilBERT, BART, AlBERT e XLNet) em diversos conjuntos
de dados utilizados em nossos experimentos sÃ£o muito pequenas.
Nossos resultados apontaram que os mÃ©todos de undersampling
NM1 [28], NM2 [28], E2SC [6], E2SC-RL (nossa proposta) e UBR
(nossa proposta) foram capazes de reduzir o viÃ©s do modelo de
classificaÃ§Ã£o, mantendo sua efetividade.
MÃ©todos de CAT baseados em Transformers demandam elevado
custo computacional no processo de aprendizado dos modelos de
classificaÃ§Ã£o, resultando em longos tempos de execuÃ§Ã£o e tambÃ©m
contribuindo significativamente para a emissÃ£o de carbono na at-
mosfera [1]. Assim, precisamos investigar o impacto desse novo
passo de prÃ©-processamento na eficiÃªncia (i.e. tempo e custo com-
putacional para geraÃ§Ã£o e classificaÃ§Ã£o) dos modelos. Dessa forma,
nossa terceira pergunta de pesquisa Ã©: PP3: Qual o impacto da apli-
caÃ§Ã£o dessa etapa adicional de prÃ©-processamento (undersampling)
em termos de eficiÃªncia? E em termos da emissÃ£o de carbono?.
Nossos resultados apontam que o uso de algumas das estratÃ©gias
de undersampling, mais especificamente UBR, NM1, E2SC-RL, NM2
e E2SC, que foram capazes nÃ£o apenas de reduzir o viÃ©s sem perda
de efetividade, mas tambÃ©m diminuÃ­ram significativamente o tempo
de treinamento dos modelos (50% em mÃ©dia), o que, consequente-
mente, contribuiu para reduÃ§Ã£o na emissÃ£o de ğ¶ğ‘‚2 (50%, em mÃ©dia)
durante a geraÃ§Ã£o e execuÃ§Ã£o dos modelos de classificaÃ§Ã£o.
Assim, as principais contribuiÃ§Ãµes deste trabalho sÃ£o:
â€¢ Mapeamento sistemÃ¡tico da literatura sobre mÃ©todos de un-
dersampling, identificando e implementando 14 mÃ©todos que
estÃ£o entre os mais utilizados. Identificamos e adaptamos
tambÃ©m um mÃ©todo de seleÃ§Ã£o de instÃ¢ncias para a tarefa
de undersampling;
â€¢ Propostas de duas novas estratÃ©gias de undersampling;
â€¢ AvaliaÃ§Ã£o das tÃ©cnicas de undersampling em conjunto com
classificadores baseado em Transformers sob trÃªs perspecti-
vas: (1) efetividade da classificaÃ§Ã£o; (2) eficiÃªncia (tempo); e
(3) capacidade de generalizaÃ§Ã£o (viÃ©s).
LEVANTAMENTO DAS ESTRATÃ‰GIAS
Nesta seÃ§Ã£o, detalhamos o processo de revisÃ£o sistemÃ¡tica da liter-
atura (RSL) [7, 8] para selecionar quais estratÃ©gias de undersampling
e seleÃ§Ã£o de instÃ¢ncias que serÃ£o avaliadas.
2.1
MÃ©todos de Undersampling
Recorremos ao mecanismo de pesquisa do Google Scholar para sub-
meter a consulta e gerar nosso conjunto inicial de artigos. O Google
Scholar foi escolhido devido Ã  sua ampla cobertura, abrangendo as
principais bibliotecas digitais de editoras como ACM, IEEE e Else-
vier, alÃ©m de repositÃ³rios de prÃ©-impressÃ£o como Arxiv. A string de
busca utilizada foi "Undersampling" e, para maximizar a abrangÃªncia
da pesquisa, o mecanismo de busca nÃ£o aplicou nenhum filtro de
local ou ano. Com base nisso, coletamos, inicialmente, um total de
500 artigos Ãºnicos que, de alguma forma, utiliza alguma estratÃ©gia
de undersampling.
Analisamos manualmente os 500 artigos, procurando identificar
os mais pertinentes para o estudo. Um artigo foi considerado rel-
evante caso utilizasse tÃ©cnicas de undersampling para reduzir des-
balanceamento, sendo que o mÃ©todo de undersampling empregado
deveria ser explicitamente mencionado (citado). Identificamos 139
artigos relevantes e, a partir deles, enumeramos todas as tÃ©cni-
cas de undersampling utilizadas, encontrando, ao todo, 32 tÃ©cnicas
diferentes. Uma tabela completa com uma descriÃ§Ã£o de todas as
estratÃ©gias identificadas estÃ¡ disponÃ­vel online 1. Optamos por con-
siderar em nossa avaliaÃ§Ã£o aqueles que foram utilizados em mais
de um dos trabalhos relevantes. Faremos nossa avaliaÃ§Ã£o sobre os
seguintes mÃ©todos:
- Links de Tomek (TL) [37]: dados dois exemplos ğ‘’ğ‘–e ğ‘’ğ‘—de difer-
entes classes, com ğ‘‘(ğ‘’ğ‘–,ğ‘’ğ‘—) representando a distÃ¢ncia entre ğ‘’ğ‘–e ğ‘’ğ‘—,
um par ğ´(ğ‘’ğ‘–,ğ‘’ğ‘—) Ã© chamado de link de Tomek se nÃ£o houver nen-
hum exemplo ğ‘’ğ‘™tal que ğ‘‘(ğ‘’ğ‘–,ğ‘’ğ‘™) < ğ‘‘(ğ‘’ğ‘–,ğ‘’ğ‘—) ou ğ‘‘(ğ‘’ğ‘—,ğ‘’ğ‘™) < ğ‘‘(ğ‘’ğ‘–,ğ‘’ğ‘—).
1https://github.com/guilherme8426/Undersampling
EstratÃ©gias de Undersampling para ReduÃ§Ã£o de ViÃ©s em ClassificaÃ§Ã£o de Texto Baseada em Transformers
WebMediaâ€™2024, Juiz de Fora, Brazil
Se dois exemplos formam um link de Tomek, entÃ£o ou um desses ex-
emplos foi classificado manualmente errado ou ambos sÃ£o exemplos
pertencentes Ã  fronteiras entre as classes e podem ser removidos.
- Condensed Nearest Neighbors (CNN)[17]: O conjunto de da-
dos ğ‘†Ã© inicializado com um exemplo da classe majoritÃ¡ria e todos
os exemplos da classe minoritÃ¡ria e um conjunto ğ‘‡Ã© criado com os
elementos que nÃ£o pertencem a ğ‘†. Cada exemplo değ‘‡Ã© classificado
pelo KNN usando ğ‘†como conjunto de treinamento. Caso o KNN
acerte a classe do exemplo, ele permanece em ğ‘‡; caso contrÃ¡rio, o
exemplo Ã© removido de ğ‘‡e colocado em ğ‘†. Esse processo se repete
atÃ© que nÃ£o ocorram mais mudanÃ§as no conjunto ğ‘†. Ao final, os
elementos de ğ‘‡sÃ£o descartados.
- One-Sided Selection (OSS)[20]: Combina o TL e uma variaÃ§Ã£o do
CNN. inicialmente, como no CNN, um conjunto ğ‘†Ã© inicializado com
todas as instÃ¢ncias da classe minoritÃ¡ria e uma da classe majoritÃ¡ria
e um conjuntoğ‘‡com o restante dos elementos, depois as instÃ¢ncias
de ğ‘‡sÃ£o classificadas com o KNN treinado em ğ‘†e cada instÃ¢ncia
classificada erroneamente Ã© colocada em ğ‘†. No final, o TL Ã© utilizado
em ğ‘†para identificar pares ambÃ­guos na fronteira da classe.
- Edited Nearest Neighbours (ENN)[39]: insere todas as instÃ¢n-
cias do conjunto original ğ‘‡no conjunto de soluÃ§Ã£o ğ‘†, utilizando
o KNN de maneira iterativa para classificar todas as instÃ¢ncias ğ‘¥
dado que ğ‘¥âˆˆğ‘†e que ğ‘¥pertenÃ§a a classe majoritÃ¡ria (considerando
o conjunto {ğ‘†âˆ’{ğ‘¥}} como possÃ­veis vizinhos). Por fim, remove as
instÃ¢ncias classificadas incorretamente.
- Repeated Edited Nearest Neighbours (RENN)[36]: ENN apli-
cado sucessivamente atÃ© que nÃ£o seja possÃ­vel remover mais pontos.
- ALL k-NN [36]: ENN aplicado sucessivamente, mas, a cada apli-
caÃ§Ã£o, o nÃºmero de vizinhos a serem considerados aumenta.
- Neighbourhood Cleaning Rule (NCR)[22]: Utiliza o KNN para
classificar todas as instÃ¢ncias da base de dados. Caso a classe pre-
vista seja diferente da classe real e a instÃ¢ncia pertenÃ§a Ã  classe
majoritÃ¡ria, a instÃ¢ncia Ã© eliminada. O NCR classifica tambÃ©m as
instÃ¢ncias da classe minoritÃ¡ria. Se a classificaÃ§Ã£o estiver incor-
reta, o mÃ©todo elimina os vizinhos mais prÃ³ximos da instÃ¢ncia que
pertencem Ã  classe majoritÃ¡ria.
- Near Miss (NM)[28]: trÃªs mÃ©todos de undersampling sÃ£o propos-
tos. O NearMiss-1 (NM1) remove as instÃ¢ncias da classe majoritÃ¡ria
que tÃªm a menor distÃ¢ncia mÃ©dia entre as k instÃ¢ncias da classe
minoritÃ¡ria. O NearMiss-2 (NM2) seleciona os elementos da classe
majoritÃ¡ria cuja distÃ¢ncia mÃ©dia para os k pontos mais distantes
da classe minoritÃ¡ria Ã© a mais baixa. JÃ¡ o NearMiss-3 (NM3) calcula,
para cada instÃ¢ncia da classe minoritÃ¡ria, as k instÃ¢ncias da classe
majoritÃ¡ria mais prÃ³ximas e as mantÃ©m na base de dados.
- SBC [41]: Todo o conjunto de treino Ã© dividido em N clusters. Para
cada um dos clusters, o nÃºmero de instÃ¢ncias a serem selecionadas
Ã© calculado com base no nÃºmero de amostras da classe majoritÃ¡ria
e da classe minoritÃ¡ria que existem no cluster. ApÃ³s isso, exemplos
da classe majoritÃ¡ria sÃ£o selecionados aleatoriamente. Por fim, o
algoritmo combina as instÃ¢ncias selecionadas de cada cluster com
as da classe minoritÃ¡ria para formar um novo conjunto.
- IHT [35]: Utiliza um classificador (c) para obter o instance hard-
ness (IH) de cada instÃ¢ncia. O IH de uma instÃ¢ncia Ã© dado por
ğ¼ğ»(< ğ‘¥ğ‘–,ğ‘¦ğ‘–>) = 1 âˆ’ğ‘(ğ‘¦ğ‘–|ğ‘¥ğ‘–,ğ‘) onde ğ‘(ğ‘¦ğ‘–|ğ‘¥ğ‘–,ğ‘) denota a probabil-
idade, gerada pelo classificador c, da instÃ¢ncia ğ‘¥ğ‘–pertencer Ã  classe
ğ‘¦ğ‘–. O IHT seleciona amostras da classe majoritÃ¡ria com baixa proba-
bilidade de pertencerem Ã  classe majoritÃ¡ria para serem removidas.
- CC-NN [24]: As instÃ¢ncias da classe majoritÃ¡ria sÃ£o divididas em
N clusters, com N sendo o nÃºmero de instÃ¢ncias da classe minoritÃ¡ria.
ApÃ³s isso, o vizinho mais prÃ³ximo do centrÃ³ide de cada um dos
clusters que pertenÃ§a Ã  classe majoritÃ¡ria Ã© escolhido para compor,
junto com as instÃ¢ncias da classe minoritÃ¡ria, o conjunto final.
- OBU [38]: Utiliza o Fuzzy c-means para dividir os dados em 2 clus-
ters, onde o cluster que tiver mais instÃ¢ncias da classe minoritÃ¡ria
Ã© chamado de ğ¶ğ‘€. Depois disso, o algoritmo remove todas as in-
stÃ¢ncias da classe majoritÃ¡ria cujo grau de pertencimento para o
CM Ã© menor que ğ›¼(hiperparÃ¢metro).
2.2
MÃ©todos de seleÃ§Ã£o de instÃ¢ncia
Apesar de terem fins diferentes, as Ã¡reas de seleÃ§Ã£o de instÃ¢ncias
(SI) e undersampling (US) sÃ£o relacionadas, pois tratam de tÃ©cni-
cas que visam selecionar um subconjunto de dados a ser usado no
treinamento do modelo e que cumpram seus objetivos: (1) no caso
de SI, melhorar a eficiÃªncia sem perda de efetividade; e (2) no caso
de US, reduzir o viÃ©s da classe majoritÃ¡ria, mantendo a efetividade.
Apesar dos objetivos finais serem diferentes, partimos da hipÃ³tese
de que hÃ¡ uma relaÃ§Ã£o subjacente entre ambas as tarefas, principal-
mente para mÃ©todos de SI baseados em reduÃ§Ã£o de redundÃ¢ncia [8],
que podem ser adaptados para remoÃ§Ã£o de instÃ¢ncias redundantes
da classe majoritÃ¡ria. Essa hipÃ³tese norteia a concepÃ§Ã£o do nosso
novo mÃ©todo de US - UBR - descrito na prÃ³xima seÃ§Ã£o e tambÃ©m nos
motivou a selecionar e adaptar trabalhos de SI para undersampling.
Uma varredura na literatura de SI aplicada a CAT nos revela
que o mÃ©todo E2SC [6, 32] Ã© o estado da arte. O mÃ©todo funciona
em duas etapas. Na primeira, calcula as probabilidades de cada in-
stÃ¢ncia ser removida. Estas probabilidades sÃ£o obtidas por meio da
confianÃ§a do classificador KNN, que Ã© calibrado (classificador cujas
previsÃµes de probabilidade de classe correspondem bem Ã  acurÃ¡cia
do classificador) [34]. Na segunda etapa, o E2SC tenta estimar qual
a taxa de reduÃ§Ã£o Ã³tima para a base de dados. ApÃ³s isso, as instÃ¢n-
cias sÃ£o amostradas aleatoriamente, ponderadas pela probabilidade
encontrada no primeiro passo. Para o nosso trabalho, realizamos
uma modificaÃ§Ã£o do E2SC, chamada E2SC_RL, que segue o mesmo
princÃ­pio do E2SC, porÃ©m, em vez do KNN como classificador, uti-
lizaremos RegressÃ£o LogÃ­stica (RL). Optamos por essa abordagem
ser um classificador igualmente calibrado e possuir baixo custo com-
putacional, inferior ao KNN. Portanto, consideramos em nossos
experimentos o E2SC e o E2SC_RL, ambos adaptados para remover
apenas instÃ¢ncias da classe majoritÃ¡ria. AlÃ©m de todos as estratÃ©-
gias apresentadas nesta seÃ§Ã£o, apresentamos a seguir nossa nova
proposta de estratÃ©gia de undersampling.
MÃ‰TODO PROPOSTO
Nesta seÃ§Ã£o, apresentamos nossa segunda contribuiÃ§Ã£o neste tra-
balho, uma nova abordagem denominada UBR (Undersampling
Baseado em RedundÃ¢ncia). Essa abordagem busca inspiraÃ§Ã£o em
tÃ©cnicas de SI. Um par de documentos Ã© considerado redundante se
apresenta alta similaridade entre si. Nossa hipÃ³tese Ã© que manter
apenas uma das instÃ¢ncias no conjunto de treinamento Ã© suficiente,
pois a presenÃ§a de ambas nÃ£o trarÃ¡ aumento significativo na apren-
dizagem do modelo. Ao se concentrar na reduÃ§Ã£o de redundÃ¢ncia
na classe majoritÃ¡ria, obtemos um potencial de reduÃ§Ã£o do des-
balanceamento e, consequentemente, do viÃ©s para essa classe. O
Algoritmo 1 detalha o pseudocÃ³digo do UBR.
WebMediaâ€™2024, Juiz de Fora, Brazil
Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos AndrÃ© GonÃ§alves, & Leonardo Rocha
Algoritmo 1: Algoritmo UBR
Input: X, ğ›¼
Output: instanciasSel
1 ğ‘‹ğ‘€ğ‘ğ‘—â†ğ‘œğ‘ğ‘¡ğ‘’ğ‘Ÿğ¼ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ (ğ‘‹,ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’= ğ‘šğ‘ğ‘—ğ‘œğ‘Ÿğ‘–ğ‘¡ğ‘ğ‘Ÿğ‘–ğ‘);
2 ğ‘‹ğ‘€ğ‘–ğ‘›â†ğ‘œğ‘ğ‘¡ğ‘’ğ‘Ÿğ¼ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ (ğ‘‹,ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’= ğ‘šğ‘–ğ‘›ğ‘œğ‘Ÿğ‘–ğ‘¡ğ‘ğ‘Ÿğ‘–ğ‘);
3 ğ‘–ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘†ğ‘’ğ‘™â†ğ‘‹ğ‘€ğ‘–ğ‘›;
4 ğ·â†ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ´ğ‘ğ‘Ÿğ‘œğ‘¥ğ‘–ğ‘šğ‘ğ‘‘ğ‘ğ‘ğ‘‰ğ‘–ğ‘§ğ‘–ğ‘›â„ğ‘œğ‘ (ğ‘‹ğ‘€ğ‘ğ‘—) ;
5 ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ â†ğ‘‹ğ‘€ğ‘ğ‘—;
6 ğ‘â†
ğ‘‹ğ‘€ğ‘ğ‘—
âˆ’âˆ¥ğ‘‹ğ‘€ğ‘–ğ‘›âˆ¥;
7 while ğ‘> 0 do
ğ´, ğµâ†ğ‘ƒğ‘ğ‘Ÿğ‘€ğ‘ğ‘–ğ‘ ğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿ(ğ‘‹ğ‘€ğ‘ğ‘—, ğ·) ;
if (âˆ¥ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ [ğ´]âˆ¥> ğ›¼)ğ‘‚ğ‘…(âˆ¥ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ [ğµ]âˆ¥> ğ›¼) then
ğ‘ğ‘œğ‘›ğ‘¡ğ‘–ğ‘›ğ‘¢ğ‘’;
end
if ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ [ğ´] â‰ ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ [ğµ] then
ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ [ğ´] â†ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ [ğ´] Ãğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ [ğµ] ;
ğ‘‘ğ‘’ğ‘™ğ‘’ğ‘¡ğ‘ğ‘Ÿ(ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿ[ğµ]) ;
ğ‘= ğ‘âˆ’1 ;
end
17 end
18 ğ‘’ğ‘ ğ‘ğ‘œğ‘™â„ğ‘–ğ‘‘ğ‘œğ‘ â†ğ‘’ğ‘ ğ‘ğ‘œğ‘™â„ğ‘’ğ‘…ğ‘’ğ‘ğ‘Ÿğ‘’ğ‘ ğ‘’ğ‘›ğ‘¡ğ‘ğ‘›ğ‘¡ğ‘’(ğ‘ğ‘™ğ‘¢ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘ ) ;
19 ğ‘–ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘†ğ‘’ğ‘™â†ğ‘–ğ‘›ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ğ‘ ğ‘†ğ‘’ğ‘™Ãğ‘’ğ‘ ğ‘ğ‘œğ‘™â„ğ‘–ğ‘‘ğ‘œğ‘ ;
Dado ğ‘‹como o conjunto total de instÃ¢ncias de treinamento, ini-
cialmente dividimos ğ‘‹em dois conjuntos, ğ‘‹ğ‘€ğ‘ğ‘—e ğ‘‹ğ‘€ğ‘–ğ‘›, onde ğ‘‹ğ‘€ğ‘ğ‘—
consiste em instÃ¢ncias de ğ‘‹pertencentes Ã  classe majoritÃ¡ria, e
ğ‘‹ğ‘€ğ‘–ğ‘›consiste em instÃ¢ncias de ğ‘‹pertencentes Ã  classe minoritÃ¡ria.
Para cada instÃ¢ncia de ğ‘‹ğ‘€ğ‘ğ‘—, calculamos a similaridade de cosseno
da instÃ¢ncia para os seus K vizinhos mais prÃ³ximos e colocamos
em uma lista ordenada ğ·.
Por questÃµes de otimizaÃ§Ã£o de tempo e de uso de memÃ³ria, uti-
lizamos uma versÃ£o aproximada do KNN [33]. ApÃ³s isso, passamos
a considerar cada instÃ¢ncia de ğ‘‹ğ‘€ğ‘ğ‘—como um cluster individual e
realizamos ğ‘iteraÃ§Ãµes, onde ğ‘= ğ‘‹ğ‘€ğ‘ğ‘—âˆ’ğ‘‹ğ‘€ğ‘–ğ‘›. Em cada iteraÃ§Ã£o,
buscamos em ğ·o par de instÃ¢ncias ğ´e ğµpertencentes a ğ‘‹ğ‘€ğ‘ğ‘—que
apresenta a maior similaridade e que estÃ£o em clusters distintos e
cujos clusters nÃ£o sejam maiores que ğ›¼(hiperparÃ¢metro do mÃ©todo
que controla a quantidade de vizinhos a ser avaliada), com o obje-
tivo de unir os clusters aos quais ğ´e ğµpertencem. Ao final, temos
|ğ‘‹ğ‘€ğ‘–ğ‘›| clusters dentro do conjunto ğ‘‹ğ‘€ğ‘ğ‘—, dos quais serÃ¡ selecionado
aleatoriamente um representante para compor, juntamente com o
conjunto ğ‘‹ğ‘€ğ‘–ğ‘›, o novo conjunto de treinamento.2
dataset
# docs
# majoritÃ¡ria
# minoritÃ¡ria
RD
Nome
sentistrength_twitter_2L
2,289
1,340
1.41
A
vader_amazon_2L
3,610
2,128
1,482
1.44
B
english_dailabor_2L
1,227
1.51
debate_2L
1,979
1,249
1.71
sentistrength_youtube_2L
2,432
1,665
2.17
E
sentistrength_rw_2L
2.19
F
vader_twitter_2L
4,196
2,897
1,299
2.23
G
tweet_semevaltest_2L
3,060
2,223
2.66
H
sentistrength_digg_2L
2.72
sentistrength_myspace_2L
5.32
J
sentistrength_bbc_2L
6.60
K
digital_music_2L
162,989
158,985
4,004
39.71
Tabela 1: ColeÃ§Ãµes de dados utilizadas nos experimentos. A
coluna â€œnomeâ€ contÃ©m como a base vai ser referenciada.
2Nossa tÃ©cnica Ã© limitada a problemas de classificaÃ§Ã£o binÃ¡rios. Deixamos para o futuro
a extensÃ£o da abordagem para problemas multi-rÃ³tulo.
CONFIGURAÃ‡ÃƒO EXPERIMENTAL
4.1
Base de dados
Consideramos 12 datasets, com diferentes nÃ­veis de desbalancea-
mento. A Tabela 1 mostra os datasets com o nÃºmero de documentos,
nÃºmero de documentos pertencentes Ã  classe majoritÃ¡ria e Ã  mi-
noritÃ¡ria, o nome pelo qual vamos nos referir a base de dados ao
longo do trabalho e a razÃ£o de desbalanceamento (RD)[31], mÃ©trica
que demonstra o quÃ£o desbalanceado Ã© uma base de dados (quanto
maior for a RD mais desbalanceado Ã© a base de dados). O RD Ã©
calculado como sendo ğ‘…ğ·= ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘šğ‘ğ‘—ğ‘œğ‘Ÿğ‘–ğ‘¡ğ‘ğ‘Ÿğ‘–ğ‘
ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘šğ‘–ğ‘›ğ‘œğ‘Ÿğ‘–ğ‘¡ğ‘ğ‘Ÿğ‘–ğ‘.
4.2
MÃ©todo de ClassificaÃ§Ã£o de Texto
Consideramos mÃ©todos de CAT baseados em Transformers BART
[23], RoBERTa [25] e BERT[11], que atualmente se apresentam
como os melhores entre os mÃ©todos de classificaÃ§Ã£o utilizados na
literatura para tarefa de AnÃ¡lise de Sentimento [8]. Para ajustar os
hiperparÃ¢metros, utilizamos a mesma metodologia discutida em [8].
Assim, fixamos a taxa de aprendizado inicial como 5 Ã— 10âˆ’5, o
nÃºmero mÃ¡ximo de Ã©pocas como 20 e a paciÃªncia como 5 Ã©pocas. Por
fim, realizamos um grid search em max_len (150 e 256) e batch_size
(16, 32 e 64), pois esses valores especificados impactam diretamente
na eficiÃªncia e efetividade do modelo. Utilizamos, tambÃ©m, 6 classifi-
cadores tradicionais: KNN, Random Forest [3], RegressÃ£o LogÃ­stica
(RL) [40], SVM [2], XGBoost (XGB) [4] e LightGBM (LGBM) [19].
4.3
MÃ©tricas e Protocolo Experimental
Nossa avaliaÃ§Ã£o Ã© feita sob trÃªs perspectivas: (1) efetividade da
classificaÃ§Ã£o; (2) capacidade de generalizaÃ§Ã£o dos modelos (viÃ©s);
e (3) eficiÃªncia (tempo e emissÃ£o de ğ¶ğ‘‚2). A efetividade Ã© avaliada
utilizando a Macro Average F1 (MacroF1). A capacidade de general-
izaÃ§Ã£o Ã© medida pela mÃ©trica TPRGap apresentada em [9], definida
na EquaÃ§Ã£o 1, onde ğ‘‡ğ‘ƒğ‘…(ğ‘–) Ã© true positive rate da classe ğ‘–, ğ‘‡Ã© o
nÃºmero total de classes, ğ‘Ã© o fator de normalizaÃ§Ã£o, que Ã© igual
ao nÃºmero de pares de classes que comparamos  ğ‘‡
.
ğ‘‡ğ‘ƒğ‘…ğºğ‘ğ‘=
âˆ‘ï¸
ğ‘–,ğ‘—ğœ–ğ‘‡
|ğ‘‡ğ‘ƒğ‘…(ğ‘–) âˆ’ğ‘‡ğ‘ƒğ‘…(ğ‘—) |
ğ‘
(1)
A eficiÃªncia Ã© medida com base no custo de cada mÃ©todo em termos
do tempo total necessÃ¡rio para construir o modelo e realizar as clasi-
ficaÃ§Ãµes. O Speedup Ã© calculado como ğ‘†= ğ‘‡ğ‘¤ğ‘œ
ğ‘‡ğ‘¤, onde ğ‘‡ğ‘¤Ã© o tempo
total gasto na construÃ§Ã£o do modelo, mais o tempo da classificaÃ§Ã£o,
usando alguma abordagem de undersampling, eğ‘‡ğ‘¤ğ‘œÃ© o tempo total
gasto na execuÃ§Ã£o (modelo e classificaÃ§Ã£o) sem a fase de undersam-
pling. A emissÃ£o değ¶ğ‘‚2 Ã© o equivalente de diÃ³xido de carbono gasto
para treinamento de um modelo e classificaÃ§Ã£o baseado em [21].
Os experimentos foram realizados na AWS. Para as bases de
dados de A atÃ© K, as etapas undersampling, que demandam estri-
tamente processamento em CPU, utilizaram uma instÃ¢ncia do tipo
c6a.4xlarge e a classificaÃ§Ã£o, que demanda hardware especializado
(GPU), instÃ¢ncias do tipo g4dn.xlarge. Para a base L, que Ã© bem
maior que as demais, demandou um poder computacional maior e
ambas as etapas foram executadas em instÃ¢ncias do tipo g5.4xlarge.
As bases de dados foram divididas utilizando o mÃ©todo de validaÃ§Ã£o
cruzada com 5 partiÃ§Ãµes (base L) ou 10 partiÃ§Ãµes (demais bases).
As comparaÃ§Ãµes foram realizadas utilizando o mÃ©todo estatÃ­stico
Teste-T com correÃ§Ã£o de Bonferroni [8].
EstratÃ©gias de Undersampling para ReduÃ§Ã£o de ViÃ©s em ClassificaÃ§Ã£o de Texto Baseada em Transformers
WebMediaâ€™2024, Juiz de Fora, Brazil
RoBERTa
BART
BERT
SVM
LR
RF
XGB
LGBM
KNN
dataset
Macro F1
TPRGap
Macro F1
TPRGap
Macro F1
TPRGap
Macro F1
TPRGap
Macro F1
TPRGap
Macro F1
TPRGap
Macro F1
TPRGap
Macro F1
TPRGap
Macro F1
TPRGap
A
88.6(0.7)
0.063
89.3(1.1)
0.048
84.3(1.7)
0.050
71.8(2.5)
0.187
71.4(2.5)
0.228
67.0(2.4)
0.370
64.9(2.4)
0.417
63.2(3.2)
0.375
64.3(3.1)
0.478
B
89.0(0.7)
0.065
88.3(1.4)
0.079
86.9(0.8)
0.057
72.1(1.5)
0.257
72.9(1.5)
0.209
68.6(1.8)
0.422
67.6(1.4)
0.247
69.4(2.7)
0.250
65.9(2.8)
0.498
93.3(1.1)
0.041
93.7(1.2)
0.036
89.1(2.2)
0.063
79.3(3.1)
0.111
80.4(2.1)
0.117
75.7(2.8)
0.221
75.0(1.5)
0.171
68.9(5.9)
0.208
76.9(2.1)
0.166
89.3(1.2)
0.076
89.1(1.1)
0.085
85.5(2.0)
0.146
76.4(2.1)
0.213
75.6(3.6)
0.223
73.3(3.0)
0.271
71.5(1.8)
0.302
72.8(3.4)
0.296
72.7(3.2)
0.330
E
89.7(1.9)
0.096
88.9(1.7)
0.117
86.1(1.8)
0.134
79.0(1.7)
0.215
78.6(2.0)
0.245
72.6(4.0)
0.257
71.1(1.7)
0.472
71.7(3.7)
0.385
73.3(3.4)
0.263
F
87.3(3.4)
0.126
88.0(3.3)
0.128
80.9(2.5)
0.202
69.1(3.4)
0.421
68.2(2.8)
0.471
59.3(4.1)
0.698
63.1(5.0)
0.582
65.8(4.2)
0.454
58.8(2.2)
0.698
G
94.2(1.0)
0.160
93.7(1.0)
0.053
88.0(1.3)
0.108
82.0(1.0)
0.238
80.4(1.4)
0.320
72.6(1.9)
0.526
74.0(1.4)
0.476
74.0(2.8)
0.372
75.4(1.3)
0.454
H
90.1(1.5)
0.102
90.1(1.6)
0.099
86.4(1.9)
0.125
70.9(2.0)
0.404
71.9(1.7)
0.399
64.5(2.0)
0.615
64.0(1.9)
0.660
63.9(4.4)
0.633
60.8(1.5)
0.654
83.8(5.0)
0.190
81.6(5.6)
0.198
79.1(3.6)
0.290
67.0(5.6)
0.539
63.0(6.8)
0.619
54.9(5.1)
0.731
56.7(5.2)
0.665
56.4(5.3)
0.598
55.2(6.4)
0.800
J
83.2(3.4)
0.333
83.0(5.8)
0.283
79.8(4.9)
0.350
68.1(3.8)
0.610
63.1(6.4)
0.733
59.8(4.6)
0.809
59.2(3.5)
0.803
58.4(10.5)
0.763
56.5(4.4)
0.875
K
81.0(4.5)
0.350
78.0(6.1)
0.410
76.4(4.4)
0.447
50.5(5.0)
0.944
53.3(4.7)
0.914
54.3(5.7)
0.888
53.4(5.3)
0.898
55.7(11.2)
0.833
46.4(0.1)
0.998
87.8(2.5)
0.308
88.6(1.2)
0.296
85.3(0.7)
0.383
78.7(0.3)
0.601
78.2(0.7)
0.562
78.9(0.4)
0.561
72.0(0.3)
0.698
73.6(0.7)
0.668
60.9(0.5)
0.866
MÃ©dia:
0.159
0.153
0.196
0.395
0.420
0.531
0.533
0.486
0.590
Tabela 2: Resultados de Macro-F1 e TPRGap dos classificadores. CÃ©lulas em negrito sÃ£o os maiores valores numÃ©ricos para uma
base de dados e cÃ©lulas em verde sÃ£o estatisticamente equivalentes Ã  classificaÃ§Ã£o de maior valor numÃ©rico.
ANÃLISE DOS RESULTADOS
5.1
PP1: ComparaÃ§Ã£o entre mÃ©todos de CAT
Para responder a PP1 (Como algoritmos estado da arte recentes,
baseados em Transformers, sÃ£o afetados pelo desbalanceamento de
classes em tarefas de anÃ¡lise de sentimentos? HÃ¡ espaÃ§o para melho-
rias?), comparamos os classificadores tradicionais KNN, RF, RL,
SVM, XGB e LGBM com os baseados em Transformers RoBERTa,
BART e BERT.
A Tabela 2 apresenta os resultados de MacroF1 e TPRGap para
estes classificadores. Como primeira anÃ¡lise, podemos destacar a
superioridade, em termos de efetividade, dos classificadores basea-
dos em Transformers quando comparados aos classificadores tradi-
cionais â€“ estes foram inferiores (estatisticamente) aos Transformers
em todas as 12 bases de dados consideradas, resultado condizente
com a literatura [7]. JÃ¡ dentre os classificadores baseados em Trans-
formers, o RoBERTa e o BART se destacam, ambos com resultados de
classificaÃ§Ã£o estatisticamente equivalentes em todas bases. O BERT,
por sua vez, Ã© estatisticamente equivalente ao RoBERTa e ao BART
em apenas 4 das 12 bases de dados. Por fim, quando analisamos
os valores numÃ©ricos absolutos de cada classificador, o modelo
RoBERTa produz os maiores valores de MacroF1 em 8 coleÃ§Ãµes
enquanto o BART o faz em 4 delas, reforÃ§ando a ideia da literatura
[8] de que o RoBERTa produz resultados condizentes com o estado
da arte atual de anÃ¡lise de sentimentos. Por isso, nas anÃ¡lises das
prÃ³ximas seÃ§Ãµes, passaremos a utilizar apenas o RoBERTa.
Focando agora no viÃ©s (TPRGap mÃ©dio) das abordagens (quanto
menor TPRGap, menor viÃ©s), observamos que os Transformers ap-
resentam menor viÃ©s quando comparados aos mÃ©todos de CAT
tradicionais. Para os classificadores tradicionais, o mÃ©todo que
obteve os melhores valores foi o SVM com um TPRGap mÃ©dio
de 0.395, o que Ã© mais que o dobro do TPRGap mÃ©dio dos mÃ©todos
baseados em Transformers que conseguiram 0.159 (RoBERTa), 0.153
(BART) e 0.196 (BERT). Esse resultado Ã© muito interessante e atÃ©
onde sabemos nÃ£o foi reportado na literatura - a boa capacidade
dos Transformers de lidar com desbalanceamento de dados.
Apesar disso, os Transformers ainda apresentam resultados de
TPRGap alto em bases de dados que tÃªm um desbalanceamento
elevado, como Ã© o caso das bases J, K e L, com RD igual a 5.32, 6.60
e 39.71, respectivamente. Isso nos mostra que ainda hÃ¡ espaÃ§o para
melhorias, isto Ã©, espaÃ§o para usar tÃ©cnicas capazes de reduzir o
viÃ©s dos modelos Transformers.
Portanto, os classificadores baseados em Transformers conseguem
gerar modelos que, alÃ©m da efetividade estado da arte, apresentam
um viÃ©s consideravelmente menor quando comparados aos classi-
ficadores tradicionais. AlÃ©m disso, observamos que, mesmo para
os Transformers, ainda hÃ¡ espaÃ§o considerÃ¡vel de melhoria. Esse
espaÃ§o Ã© explorado a seguir.
5.2
PP2: Efetividade e ViÃ©s de CAT com
undersampling
Na Tabela 3, apresentamos os resultados de efetividade obtidos por
meio da aplicaÃ§Ã£o dos mÃ©todos de US juntamente com o classifi-
cador RoBERTa. A coluna â€œNoUnderâ€ apresenta o resultado sem o
undersampling do conjunto de treinamento. Um ponto importante
Ã© que, para todos os mÃ©todos que permitem hiperparametrizaÃ§Ã£o
no que tange a quantidade de instÃ¢ncias a serem removidas (UBR,
E2SC, E2SC_RL, NM1, NM2, IHT e CC_NN), limitamos a remoÃ§Ã£o
de no mÃ¡ximo 50% da base de dados, pois trabalhos recentes rela-
cionados Ã  seleÃ§Ã£o de instÃ¢ncias [6] apontam que esse Ã© o limite
empÃ­rico de reduÃ§Ã£o onde ainda Ã© possÃ­vel nÃ£o ocorrer perdas na
efetividade. Os outros mÃ©todos nÃ£o foram modificados, seguindo
a polÃ­tica de remoÃ§Ã£o prÃ³pria.
Podemos observar que os mÃ©todos UBR, NM1, E2SC_RL, NM2,
E2SC, TL e OSS conseguem empate estatÃ­stico com a classificaÃ§Ã£o
sem undersampling (i.e., com o treino completo desbalanceado) em
todas as coleÃ§Ãµes analisadas. Isso demonstra que todas as tÃ©cnicas
listadas acima tem a capacidade de balancear a base sem causar
perdas de efetividade. Os demais mÃ©todos nÃ£o obtiveram bons re-
sultados em relaÃ§Ã£o aos anteriores, perdendo em 4 (IHT), 3 (OBU,
SBC, RENN e ALLKNN), 2 (NM3) ou em 1 (NCR, ENN) base(s),
respectivamente. Os mÃ©todos CNN e CC_NN sÃ£o estatisticamente
equivalentes ao US em 11 de 12 bases de dados, porÃ©m, no maior
conjunto de dados (L), ambos tiveram um tempo de undersampling
que ultrapassou o tempo de treinamento do modelo de classificaÃ§Ã£o
sem o undersampling, sendo, portanto, desconsiderados para essa
anÃ¡lise devido a sua impraticabilidade.
Na Tabela 4 apresentamos os resultados para a mÃ©trica TPRGap,
a qual mede o viÃ©s dos modelos. A coluna â€œNoUnderâ€ apresenta o
resultado sem o undersampling, enquanto que as demais apresen-
tam o TPRGap dos modelos com undersampling. As cores do fundo
das cÃ©lulas representam o quanto os modelos conseguiram reduzir
o viÃ©s do modelo comparados ao â€œNoUnderâ€. Ou seja, quanto maior
o tom de verde, maior a reduÃ§Ã£o do viÃ©s, e quanto mais vermelho,
WebMediaâ€™2024, Juiz de Fora, Brazil
Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos AndrÃ© GonÃ§alves, & Leonardo Rocha
dataset
NoUnder
UBR
NM1
E2SC_RL
NM2
E2SC
NM3
IHT
OBU
SBC
NCR
TL
OSS
RENN
ALLKNN
ENN
CNN
CC_NN
A
88.6(0.7)
88.6(0.8)
88.9(0.8)
88.8(1.1)
89.0(0.8)
88.6(1.2)
88.5(1.0)
87.7(1.2)
85.1(1.4)
87.6(1.5)
87.2(2.0)
89.2(1.2)
88.3(0.6)
85.6(0.9)
87.2(2.1)
85.6(0.9)
88.2(1.5)
88.7(1.4)
B
89.0(0.7)
88.7(1.1)
88.3(1.2)
89.1(1.1)
88.2(0.7)
88.6(1.4)
51.3(13.5)
87.8(1.5)
85.6(1.4)
87.9(1.2)
89.4(1.4)
88.7(0.9)
88.7(0.9)
83.1(8.9)
70.2(5.1)
83.4(9.0)
88.1(2.0)
90.0(1.2)
93.3(1.1)
94.3(1.4)
94.2(1.5)
93.4(1.3)
94.1(1.1)
93.8(1.6)
93.9(1.4)
92.0(1.2)
92.3(1.6)
89.3(3.3)
92.4(1.4)
93.4(1.7)
94.3(1.5)
92.5(1.7)
91.7(2.0)
92.5(1.7)
93.7(1.1)
94.5(1.4)
89.3(1.2)
87.6(1.5)
88.0(1.5)
88.7(1.7)
86.3(1.5)
88.1(1.7)
87.7(2.0)
84.3(3.2)
80.7(1.6)
87.7(1.2)
86.7(1.5)
88.4(1.5)
89.1(1.4)
83.4(2.1)
83.6(3.4)
83.4(2.1)
88.2(1.0)
81.7(13.8)
E
89.7(1.9)
87.9(1.6)
88.4(1.8)
89.4(1.7)
89.3(1.9)
89.1(1.9)
89.0(1.7)
82.3(1.4)
88.2(2.3)
79.2(4.2)
68.7(7.2)
89.9(1.6)
89.9(1.6)
55.2(3.5)
58.6(3.5)
55.2(3.5)
89.6(1.5)
89.3(1.6)
F
87.3(3.4)
82.3(3.5)
83.1(4.4)
85.4(3.5)
86.7(3.7)
88.6(3.6)
86.3(2.9)
80.6(2.2)
77.1(5.1)
86.9(3.0)
87.4(2.8)
88.4(4.0)
88.2(3.8)
81.6(3.1)
84.6(5.2)
87.7(3.6)
86.7(3.2)
84.1(3.2)
G
94.2(1.0)
92.7(0.9)
92.6(1.1)
93.1(1.2)
92.5(1.2)
92.6(1.1)
92.9(1.3)
87.9(1.1)
86.7(2.4)
92.0(0.9)
93.2(1.0)
93.4(1.4)
93.8(1.1)
91.5(1.0)
93.1(0.9)
92.9(0.8)
93.0(1.0)
93.0(1.0)
H
90.1(1.5)
88.6(1.6)
89.7(2.1)
88.5(1.5)
89.2(1.8)
89.3(1.8)
88.9(1.6)
83.0(2.0)
88.3(1.7)
88.1(0.9)
90.1(1.5)
90.3(1.1)
90.6(1.6)
86.8(1.9)
88.7(1.8)
89.2(1.3)
89.8(1.8)
88.8(1.5)
83.8(5.0)
82.9(4.5)
80.5(4.3)
80.6(4.7)
81.3(4.1)
81.3(4.7)
81.0(3.9)
74.1(4.5)
77.6(3.3)
81.0(4.6)
84.0(4.9)
87.2(4.7)
85.4(3.7)
75.8(4.4)
77.3(5.5)
81.2(5.3)
83.0(5.0)
82.4(4.6)
J
83.2(3.4)
80.1(4.2)
81.0(4.7)
81.5(5.2)
80.8(5.5)
82.9(5.0)
79.4(5.3)
74.5(3.7)
81.8(6.0)
60.2(2.9)
84.5(4.6)
83.2(4.8)
84.5(4.6)
80.7(3.9)
82.4(4.1)
84.1(3.3)
81.5(3.6)
79.9(9.5)
K
81.0(4.5)
79.3(3.1)
78.0(4.1)
78.7(4.2)
75.0(5.0)
79.2(4.7)
74.0(3.2)
73.3(4.7)
71.7(4.4)
71.0(4.5)
79.8(5.1)
78.7(4.6)
77.2(5.0)
79.4(5.0)
77.4(6.1)
77.8(5.9)
77.8(4.3)
76.7(3.7)
87.8(2.5)
81.9(4.8)
87.1(1.3)
88.7(0.3)
85.1(3.5)
88.7(0.3)
51.0(1.7)
60.3(1.5)
77.3(9.1)
30.9(1.7)
80.1(21.4)
80.0(21.4)
72.7(26.5)
69.2(3.5)
67.9(2.6)
79.8(21.2)
-
-
Tabela 3: Macro-F1 do RoBERTa utilizando as abordagens de undersampling. CÃ©lulas em negrito sÃ£o os maiores valores numÃ©ricos
para uma base de dados. CÃ©lulas em verde representam resultados que sÃ£o estatisticamente equivalentes Ã  classificaÃ§Ã£o sem
undersampling (NoUnder). CÃ©lulas com â€œ-â€ representam mÃ©todos que resultaram em um tempo superior ao tempo de classificaÃ§Ã£o
da mesma base sem o undersampling e, portanto, desconsiderado.
dataset
NoUnder
UBR
NM1
E2SC_RL
NM2
E2SC
NM3
IHT
OBU
SBC
NCR
TL
OSS
RENN
ALLKNN
ENN
CNN
CC_NN
A
0.063
0.010
0.004
0.002
0.005
0.003
0.011
0.072
0.114
0.039
0.077
0.035
0.036
0.141
0.098
0.141
0.047
0.011
B
0.065
0.043
0.026
0.034
0.013
0.033
0.692
0.075
0.100
0.012
0.048
0.060
0.060
0.188
0.445
0.166
0.027
0.023
0.041
0.002
0.003
0.000
0.018
0.007
0.022
0.059
0.019
0.149
0.038
0.029
0.025
0.061
0.062
0.061
0.002
0.011
0.076
0.005
0.043
0.019
0.019
0.006
0.020
0.107
0.097
0.013
0.032
0.052
0.042
0.143
0.108
0.143
0.006
0.070
MÃ©dia
0.061
0.015
0.019
0.014
0.014
0.012
0.186
0.078
0.083
0.053
0.049
0.044
0.041
0.133
0.178
0.128
0.021
0.029
E
0.096
0.037
0.012
0.001
0.010
0.031
0.026
0.197
0.023
0.245
0.403
0.093
0.090
0.634
0.593
0.634
0.032
0.024
F
0.126
0.006
0.047
0.029
0.054
0.025
0.036
0.132
0.144
0.024
0.043
0.108
0.134
0.111
0.034
0.010
0.000
0.011
G
0.160
0.002
0.003
0.006
0.001
0.001
0.012
0.122
0.094
0.017
0.018
0.063
0.062
0.037
0.007
0.004
0.012
0.012
H
0.102
0.030
0.000
0.006
0.021
0.020
0.001
0.158
0.007
0.035
0.028
0.085
0.077
0.072
0.021
0.007
0.016
0.024
0.190
0.037
0.027
0.040
0.036
0.006
0.063
0.212
0.066
0.029
0.018
0.118
0.131
0.158
0.136
0.046
0.006
0.037
MÃ©dia
0.135
0.023
0.018
0.017
0.025
0.017
0.027
0.164
0.067
0.070
0.102
0.093
0.099
0.202
0.158
0.140
0.013
0.022
J
0.333
0.148
0.176
0.222
0.193
0.221
0.111
0.085
0.264
0.352
0.256
0.336
0.304
0.216
0.248
0.262
0.112
0.247
K
0.350
0.182
0.209
0.215
0.210
0.226
0.064
0.059
0.173
0.047
0.237
0.361
0.400
0.287
0.324
0.324
0.193
0.329
MÃ©dia
0.342
0.165
0.192
0.218
0.202
0.224
0.087
0.072
0.219
0.199
0.247
0.349
0.352
0.251
0.286
0.293
0.153
0.288
0.308
0.182
0.207
0.214
0.208
0.216
0.198
0.067
0.245
0.619
0.434
0.443
0.579
0.045
0.042
0.403
-
-
MÃ©dia Total
0.159
0.057
0.063
0.066
0.066
0.066
0.105
0.112
0.112
0.132
0.136
0.149
0.162
0.174
0.177
0.183
-
-
Tabela 4: TPRGap dos modelos gerados pelo classificador RoBERTa em conjunto com as abordagens de undersampling utilizando
o classificador RoBERTa. Quanto mais verde a cÃ©lula, maior a reduÃ§Ã£o do viÃ©s. Quanto mais vermelho, maior o aumento do viÃ©s.
maior o agravamento do viÃ©s. Para auxiliar essa anÃ¡lise, dividimos
nossas bases em 4 grupos com relaÃ§Ã£o a seu grau de desbalancea-
mento (RD). No primeiro grupo sÃ£o as bases de dados que tÃªm um
RD atÃ© 2 (bases A, B, C, D), o segundo contÃ©m as bases com RD
maiores que 2 e menores que 5 (bases E, F, G, H e I), o terceiro aque-
las com RD maior que 5 e menor que 10 (bases J e K). Por fim, no
Ãºltimo grupo, temos apenas a base de dados L, com um RD de 39.71.
Em relaÃ§Ã£o ao viÃ©s mÃ©dio total calculado, os mÃ©todos que con-
seguiram a maior reduÃ§Ã£o de viÃ©s dos modelos em todas as 12
coleÃ§Ãµes foram UBR (viÃ©s total mÃ©dio de 0.057), NM1 (0.063), E2SC_RL
(0.066), NM2 (0.066) e E2SC (0.066), com uma reduÃ§Ã£o de quase 3
vezes comparada ao NoUnder (0.159).
Os mÃ©todos RENN, ALLKNN, ENN, que jÃ¡ estÃ£o entre os piores
em termos de efetividade, tambÃ©m desempenham mal em relaÃ§Ã£o
ao enviesamento do modelo, aumentando o viÃ©s mÃ©dio. Os mÃ©to-
dos TL e OSS, apesar de apresentarem bons resultados em termos
de efetividade, demonstram um baixo desempenho em relaÃ§Ã£o ao
enviesamento, piorando o modelo em alguns casos (em 3 datasets
cada) e tendo um TPRGap mÃ©dio total prÃ³ximo ao NoUnder â€“ 0.149
(TL) e 0.162 (OSS).
Por fim, observamos tambÃ©m que o mÃ©todo UBR â€“ que obteve os
melhores resultados quanto a mÃ©dia total de TRPGap â€“ se mostra
bastante eficaz individualmente por base, principalmente naquelas
mais desbalanceadas. Por exemplo, nas bases do grupo 3 (bases K
e J) e 4 (L), o UBR reduziu o viÃ©s do modelo NoUnder em cerca de
duas vezes, estando sempre muito prÃ³ximo do menor viÃ©s geral
alcanÃ§ado por qualquer mÃ©todo para essas bases. ObservaÃ§Ã£o sim-
ilar Ã© vÃ¡lida para os outros dois grupos: UBR sempre aparece entre
os melhores resultados. O E2SC tambÃ©m Ã© bastante competitivo,
apresentando os melhores resultados mÃ©dios para os grupos 1 e 2
e estando, tambÃ©m, entre os melhores nos demais grupos.
Sumarizando, conseguimos, com as anÃ¡lises reportadas acima,
responder positivamente Ã  PP2 (MÃ©todos de undersampling, apli-
cados juntamente com classificadores baseados em Transformers, sÃ£o
capazes de reduzir o viÃ©s dos modelos de classificaÃ§Ã£o? Qual o impacto
dessa combinaÃ§Ã£o na efetividade do modelo?), pois os mÃ©todos UBR,
NM1, E2SC_RL, NM2 e E2SC sÃ£o capazes de significativamente re-
duzir o viÃ©s do modelo, sem perda de efetividade em todas as bases.
5.3
PP3: EficiÃªncia de CAT com undersampling
Analisamos aqui os mÃ©todos de US em relaÃ§Ã£o Ã  sua eficiÃªncia,
buscando verificar qual o impacto dessa nova etapa de prÃ©-proces-
samento dos dados no tempo total e na emissÃ£o total de ğ¶ğ‘‚2 prove-
niente do treinamento dos modelos. A Tabela 5 apresenta o speedup
produzido pelos mÃ©todos de US. Conforme mencionamos na SeÃ§Ã£o
4.3, o speedup Ã© calculado pela razÃ£o entre o tempo total gasto
na construÃ§Ã£o do modelo, mais o tempo da classificaÃ§Ã£o, usando
alguma abordagem de undersampling pelo tempo total gasto na
execuÃ§Ã£o (modelo e classificaÃ§Ã£o) sem a fase de undersampling.
EstratÃ©gias de Undersampling para ReduÃ§Ã£o de ViÃ©s em ClassificaÃ§Ã£o de Texto Baseada em Transformers
WebMediaâ€™2024, Juiz de Fora, Brazil
dataset
UBR
NM1
E2SC_RL
NM2
E2SC
NM3
IHT
OBU
SBC
NCR
TL
OSS
RENN
ALLKNN
ENN
CNN
CC_NN
A
1.209
1.076
1.094
1.135
1.178
1.096
1.181
1.374
1.216
1.210
0.929
0.961
1.376
1.230
1.415
1.243
1.193
B
1.203
1.163
1.273
1.114
1.099
1.588
1.230
1.342
1.364
0.988
0.962
0.990
1.513
1.452
1.476
1.005
1.186
1.315
1.237
1.400
1.096
1.253
1.247
1.115
1.214
1.638
1.223
0.873
0.885
1.039
1.120
1.070
1.361
1.202
1.558
1.469
1.712
1.450
1.456
1.493
1.402
1.282
1.637
1.516
1.185
1.150
1.854
1.447
1.966
1.519
1.500
E
1.450
1.312
1.569
1.312
1.361
1.400
1.182
1.381
1.769
1.607
0.937
0.948
1.611
1.641
1.663
1.176
1.467
F
1.534
1.299
1.371
1.450
1.666
1.544
1.627
1.491
1.507
1.413
1.068
1.065
1.416
1.632
1.504
1.601
1.529
G
1.527
1.530
1.518
1.374
1.354
1.414
1.298
1.329
1.444
1.122
0.946
0.995
1.220
1.159
1.270
1.310
1.521
H
1.749
1.659
1.950
1.619
1.788
1.757
1.668
1.607
1.728
1.319
1.055
1.067
1.771
1.587
1.395
1.494
1.867
1.657
1.923
1.635
1.601
1.609
1.519
1.634
1.331
1.564
1.401
1.034
1.014
1.516
1.751
1.537
1.510
1.612
J
1.487
1.730
1.617
1.523
1.876
2.128
1.535
1.302
2.861
0.877
1.003
0.800
0.998
0.977
0.990
2.283
1.608
K
1.695
1.691
1.802
1.621
1.741
3.054
1.602
1.411
3.433
1.487
1.107
0.972
1.220
1.341
1.335
2.377
1.442
2.662
2.709
2.903
2.867
3.039
39.486
2.103
1.777
12.498
1.038
0.892
1.318
0.946
1.713
1.230
-
-
MÃ©dia
1.587
1.566
1.654
1.513
1.618
4.811
1.465
1.404
2.722
1.267
0.999
1.014
1.373
1.421
1.404
-
-
Tabela 5: Resultados de Speedup no custo total (tempo) para geraÃ§Ã£o dos modelos utilizando o classificador RoBERTa em
conjunto com as abordagens de undersampling. Quanto mais verde a cÃ©lula, maior a reduÃ§Ã£o no tempo total de treinamento
em relaÃ§Ã£o a abordagem sem undersampling. Quanto mais vermelho, maior o tempo.
dataset
NoUnder
UBR
NM1
E2SC_RL
NM2
E2SC
NM3
IHT
OBU
SBC
NCR
TL
OSS
RENN
ALLKNN
ENN
CNN
CC_NN
A
55.537
45.884
51.580
50.740
48.897
47.114
50.650
46.966
40.362
43.922
45.838
59.770
57.725
40.322
45.119
39.218
40.892
44.769
B
83.539
69.377
71.793
65.550
74.933
75.923
52.539
67.865
62.154
59.487
84.470
86.764
84.280
55.137
57.481
56.526
66.378
66.234
34.265
26.042
27.693
24.463
31.241
27.324
27.460
30.724
28.192
20.567
27.991
39.227
38.706
32.962
30.580
32.013
24.429
27.903
93.391
59.893
63.529
54.531
64.380
64.097
62.535
66.566
72.778
56.550
61.574
78.756
81.160
50.329
64.525
47.462
57.948
61.228
E
55.470
38.202
42.243
35.322
42.254
40.692
39.576
46.877
40.118
30.730
34.474
59.146
58.448
34.394
33.765
33.315
41.039
35.803
F
36.458
23.745
28.052
26.563
25.116
21.848
23.591
22.375
24.414
23.945
25.780
34.099
34.192
25.725
22.307
24.220
22.403
23.493
G
171.805
112.413
112.145
113.060
124.901
126.778
121.423
132.204
129.121
116.158
152.980
181.434
172.539
140.629
148.092
135.182
117.260
108.297
H
78.329
44.724
47.164
40.116
48.316
43.737
44.516
46.895
48.635
41.999
59.281
74.156
73.297
44.120
49.254
56.096
43.587
39.587
22.538
13.581
11.704
13.769
14.060
13.986
14.816
13.768
16.906
14.135
16.061
21.784
22.209
14.847
12.854
14.647
14.468
13.676
J
21.994
14.773
12.700
13.592
14.429
11.708
10.321
14.307
16.869
7.486
25.071
21.912
27.473
22.023
22.498
22.193
9.291
13.296
K
23.693
13.934
13.980
13.114
14.579
13.568
7.724
14.747
16.740
6.504
15.897
21.369
24.348
19.383
17.626
17.710
9.510
15.948
2,552.335
942.877
938.264
876.957
879.055
834.978
60.623
1,209.117
1,414.486
117.465
2,324.505
2,760.191
1,831.865
1,210.973
1,245.247
1,943.847
-
-
Tabela 6: EmissÃ£o de Carbono (ğ¶ğ‘‚2) para geraÃ§Ã£o dos modelos utilizando o classificador RoBERTa em conjunto com as
abordagens de undersampling. Quanto mais verde a cÃ©lula, maior a reduÃ§Ã£o da emissÃ£o em relaÃ§Ã£o a abordagem sem undersampling.
Podemos observar que, com exceÃ§Ã£o do TL, todos os mÃ©todos,
em mÃ©dia, conseguiram manter ou reduzir o tempo em comparaÃ§Ã£o
com o RoBERTa aplicado aos dados originais (sem undersampling).
Os mÃ©todos UBR, NM1, E2SC_RL, NM2 e E2SC, que nas anÃ¡lises
anteriores se mostraram superiores quantos aos critÃ©rios de efe-
tividade e reduÃ§Ã£o do enviesamento, conseguem tambÃ©m um bom
desempenho no critÃ©rio de eficiÃªncia. Os speedups alcanÃ§ados, re-
spectivamente, de 1.587, 1.566, 1.654, 1.513 e 1.618 sÃ£o muito bons.
Juntamente com o NM3 (4.811) e SBC (2.722), esses sÃ£o os mÃ©todos
com maior ganho de speedup. Contudo, vale lembrar que o NM3 e o
SBC geram perdas de efetividade para algumas coleÃ§Ãµes (Tabela 3)
ao produzir os respectivos ganhos de speedup.
Por fim, na Tabela 6, apresentamos os valores de emissÃ£o de ğ¶ğ‘‚2
(em g) produzido pelos mÃ©todos de undersampling. Assim como
causaram perda de eficiÃªncia, os mÃ©todos TL e OSS tambÃ©m pro-
duzem um aumento de emissÃ£o de ğ¶ğ‘‚2 para algumas bases. JÃ¡
todos os demais mÃ©todos, em menor ou maior grau, geram alguma
reduÃ§Ã£o de emissÃ£o. Para as bases de dados de A a K, a emissÃ£o de
carbono Ã© muito pequena quando comparada a base L, que Ã© ordens
de magnitude maior que as demais. Por essa mesma razÃ£o, o tempo
de processamento de L Ã© muito maior, mesmo ela sendo executada
em uma mÃ¡quina de maior poder computacional. Por isso, nossa
anÃ¡lise nesse critÃ©rio focarÃ¡ nessa base. Ao analisar a emissÃ£o dos
mÃ©todos de undersampling para a base de dados L, observamos que
os mÃ©todos UBR (emissÃ£o 942.877 g ğ¶ğ‘‚2), NM1 (938.264 g ğ¶ğ‘‚2),
E2SC_RL (876.957 g ğ¶ğ‘‚2), NM2 (879.055 g ğ¶ğ‘‚2) e E2SC (834.978
g ğ¶ğ‘‚2), os mesmos mÃ©todos destacados nas anÃ¡lises anteriores,
tambÃ©m conseguem reduzir mais que pela metade a emissÃ£o em
comparaÃ§Ã£o com o NoUnder (2,552.335 g ğ¶ğ‘‚2). Traduzindo esses
nÃºmeros para exemplos ilustrativos, podemos dizer que a emissÃ£o
antes era equivalente a 2.73 meses de uma Ã¡rvore sequestrando car-
bono ou a emissÃ£o de 14.40 km percorridos por um carro [21]. JÃ¡ a
emissÃ£o apÃ³s o undersampling, considerando o UBR como exemplo,
seria equivalente a 1.03 meses de sequestro de carbono feito por
uma Ã¡rvore ou a emissÃ£o de de 5.41 Km percorridos por um carro
de passageiros. Se individualmente essa parece ser uma reduÃ§Ã£o pe-
quena, se considerarmos milhÃµes de mÃ¡quinas ao redor do mundo
rodando processos similares todos os dias, dezenas ou centenas de
vezes, essa reduÃ§Ã£o pode passar a ser considerÃ¡vel.
Voltando Ã  nossa PP3 (Qual o impacto da aplicaÃ§Ã£o dessa etapa
adicional de prÃ©-processamento (undersampling) em termos de efi-
ciÃªncia? E em termos da emissÃ£o de carbono?), temos que os mÃ©todos
UBR, NM1, E2SC_RL, NM2 e E2SC conseguem reduzir o enviesa-
mento do modelo, mantendo a efetividade e reduzindo o tempo de
treinamento dos modelos e, consequentemente, as emissÃµes de ğ¶ğ‘‚2.
5.4
DiscussÃ£o Final
Dadas as anÃ¡lises apresentadas nesta seÃ§Ã£o, onde os mÃ©todos de
undersampling foram avaliados quanto Ã  sua efetividade, sua capaci-
dade reduzir o enviesamento dos modelos e sua eficiÃªncia, podemos
concluir que os melhores mÃ©todos de undersampling analisados
foram UBR, NM1, E2SC_RL, NM2 e E2SC. Todos eles conseguiram
reduzir o enviesamento do modelo para a classe majoritÃ¡ria sem
WebMediaâ€™2024, Juiz de Fora, Brazil
Guilherme Fonseca, Gabriel Prenassi, Washington Cunha, Marcos AndrÃ© GonÃ§alves, & Leonardo Rocha
produzir nenhum tipo de perda de efetividade global (em termos
de MacroF1). Esses mÃ©todos tambÃ©m apresentaram uma reduÃ§Ã£o
no tempo de treinamento do modelo com uma consequente re-
duÃ§Ã£o na emissÃ£o de ğ¶ğ‘‚2. Das estratÃ©gias que se destacaram, duas
foram originalmente propostas neste trabalho - UBR e E2SC_RL.
Em particular a UBR foi aquela que apresentou os resultados mais
consistentes de reduÃ§Ã£o de enviesamento sem perda de efetividade,
com um bom speedup e reduÃ§Ã£o de emissÃ£o de ğ¶ğ‘‚2, sendo nossa
recomendaÃ§Ã£o final para o problema, se tivermos de fazer uma.
CONCLUSÃ•ES E TRABALHOS FUTUROS
O impacto do desbalanceamento de classes, relacionado ao viÃ©s de
um classificador para a classe majoritÃ¡ria, em estratÃ©gias do estado
da arte de CAT baseadas em Transformers, tem sido pouco discutido
na literatura [5]. Neste trabalho, apresentamos uma avaliaÃ§Ã£o detal-
hada de mÃ©todos de undersampling (US) aplicados em conjunto com
algoritmos baseados em Transformers na tarefa de AnÃ¡lise de Sen-
timento. Primeiramente, realizamos uma anÃ¡lise comparativa entre
mÃ©todos de classificaÃ§Ã£o baseados em Transformers e tradicionais
sob duas perspectivas: efetividade e enviesamento. Essa anÃ¡lise rev-
elou que, alÃ©m de mais efetivos, como conhecidos, os Transformers
sÃ£o capazes de lidar de forma mais adequada com o problema do viÃ©s
que os algoritmos tradicionais. Nossos resultados experimentais
tambÃ©m indicaram que ainda existe espaÃ§o para melhoria, princi-
palmente em bases de dados com um desbalanceamento maior.
Baseado em um mapeamento da literatura sobre undersampling,
selecionamos e implementamos os 14 mÃ©todos mais utilizados, alÃ©m
de adaptarmos diretamente um mÃ©todo de seleÃ§Ã£o de instÃ¢ncias
para a tarefa de undersampling devido a conexÃµes entre as tarefas.
Propomos, tambÃ©m, duas novas estratÃ©gias de US: E2SC_RL e UBR,
totalizando em um conjunto de 17 mÃ©todos a serem comparados.
Uma avaliaÃ§Ã£o experimental vasta, utilizando esses 17 mÃ©todos
e 12 bases de dados revelou que um conjunto de cinco mÃ©todos de
undersampling â€“ UBR (nossa proposta), NM1, E2SC_RL (nossa pro-
posta), NM2, E2SC â€“ foram capazes de reduzir o viÃ©s dos modelos
de CAT quando comparados com modelos sem undersampling sem
perdas de efetividade (qualidade da classificaÃ§Ã£o). AlÃ©m disso, esses
mesmos mÃ©todos produziram uma reduÃ§Ã£o significativa no tempo
de treino e na emissÃ£o de ğ¶ğ‘‚2 no treinamento dos modelos Trans-
formers. Entre esses 5 mÃ©todos, o UBR apresentou os resultados
mais consistentes considerando todos os critÃ©rios analisados.
Como trabalhos futuro, visamos estender o presente estudo con-
siderando, tambÃ©m, outros cenÃ¡rios de CAT, como multiclasses
e/ou hierÃ¡rquico, alÃ©m de avaliar outros algoritmos de CAT alÃ©m
do RoBERTa, tais como BERT e BART. Ademais, considerando que
a eficÃ¡cia dos LLMs recentes em comparaÃ§Ã£o com modelos anteri-
ores baseados em Transformer, como o RoBERTa, para anÃ¡lise de
sentimentos e propÃ³sitos de CAT ainda nÃ£o estÃ¡ clara [10], e que,
quando LLMs superam alguns Transformers de 1a e 2a geraÃ§Ã£o, os
ganhos sÃ£o tipicamente de apenas alguns pontos percentuais [10],
consideramos incerto se esses ganhos marginais se traduzem em
benefÃ­cios prÃ¡ticos em aplicaÃ§Ãµes do mundo real. Desta forma, em
trabalhos futuros, planejamos realizar uma anÃ¡lise completa sobre
o custo-benefÃ­cio dos LLMs em relaÃ§Ã£o aos Transformers de 1a e 2a
geraÃ§Ã£o, de modo a habilitar a aplicaÃ§Ã£o dos mÃ©todos de undersam-
pling como etapas de prÃ©-processamento de LLMs recentes.
AGRADECIMENTOS
Este trabalho foi financiado por CNPq, CAPES, Fapemig, FAPESP,
CIIA-SaÃºde e AWS.
